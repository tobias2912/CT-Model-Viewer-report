
@misc{materialise_materialise_2020,
	title = {Materialise {Introduces} {VR} {Capabilities} for {Medical} {Planning} in {Mimics} {Viewer} {\textbar} {Materialise}},
	url = {https://www.materialise.com/en/press-releases/vr-capabilities-for-medical-planning-mimics-viewer},
	language = {en},
	urldate = {2021-06-01},
	author = {materialise},
	month = nov,
	year = {2020},
	file = {Snapshot:/home/tei/Zotero/storage/GQT6F984/vr-capabilities-for-medical-planning-mimics-viewer.html:text/html},
}

@article{mishra_virtual_2019,
	title = {Virtual preoperative planning and {3D} printing are valuable for the management of complex orthopaedic trauma},
	volume = {22},
	issn = {1008-1275},
	doi = {10.1016/j.cjtee.2019.07.006},
	abstract = {PURPOSE: The technology of 3D printing (3DP) exists for quite some time, but it is still not utilized to its full potential in the field of orthopaedics and traumatology, such as underestimating its worth in virtual preoperative planning (VPP) and designing various models, templates, and jigs. It can be a significant tool in the reduction of surgical morbidity and better surgical outcome avoiding various associated complications.
METHODS: An observational study was done including 91 cases of complex trauma presented in our institution requiring operative fixation. Virtual preoperative planning and 3DP were used in the management of these fractures. Surgeons managing these cases were given a set of questionnaire and responses were recorded and assessed as a quantitative data.
RESULTS: In all the 91 cases, where VPP and 3DP were used, the surgeons were satisfied with the outcome which they got intraoperatively and postoperatively. Surgical time was reduced, with a better outcome. Three dimensional models of complex fracture were helpful in understanding the anatomy and sketching out the plans for optimum reduction and fixation. The average score of the questionnaire was 4.5, out of a maximum of 6, suggesting a positive role of 3DP in orthopaedics.
CONCLUSION: 3DP is useful in complex trauma management by accurate reduction and placement of implants, reduction of surgical time and with a better outcome. Although there is an initial learning curve to understand and execute the VPP and 3DP, these become easier with practice and experience.},
	language = {eng},
	number = {6},
	journal = {Chinese Journal of Traumatology = Zhonghua Chuang Shang Za Zhi},
	author = {Mishra, Abhishek and Verma, Tarun and Vaish, Abhishek and Vaish, Riya and Vaishya, Raju and Maini, Lalit},
	month = dec,
	year = {2019},
	pmid = {31668700},
	pmcid = {PMC6921216},
	keywords = {Adult, Bone fractures, Fracture dislocation, Fracture Dislocation, Fractures, Bone, Humans, Male, Operative Time, Orthopedic Procedures, Orthopedic Surgeons, Patient Care Planning, Printing, Three-Dimensional, Surveys and Questionnaires, Three-dimensional printing, Tomography, X-Ray Computed, Treatment Outcome, Virtual Reality, Wounds and Injuries, X-ray computed tomography, Young Adult},
	pages = {350--355},
	file = {Full Text:/home/tei/Zotero/storage/TVQ3UZEY/Mishra et al. - 2019 - Virtual preoperative planning and 3D printing are .pdf:application/pdf},
}

@article{vertemati_virtual_2019,
	title = {A {Virtual} {Reality} {Environment} to {Visualize} {Three}-{Dimensional} {Patient}-{Specific} {Models} by a {Mobile} {Head}-{Mounted} {Display}},
	volume = {26},
	issn = {1553-3506},
	url = {https://doi.org/10.1177/1553350618822860},
	doi = {10.1177/1553350618822860},
	abstract = {Introduction. With the availability of low-cost head-mounted displays (HMDs), virtual reality environments (VREs) are increasingly being used in medicine for teaching and clinical purposes. Our aim was to develop an interactive, user-friendly VRE for tridimensional visualization of patient-specific organs, establishing a workflow to transfer 3-dimensional (3D) models from imaging datasets to our immersive VRE. Materials and Methods. This original VRE model was built using open-source software and a mobile HMD, Samsung Gear VR. For its validation, we enrolled 33 volunteers: morphologists (n = 11), trainee surgeons (n = 15), and expert surgeons (n = 7). They tried our VRE and then filled in an original 5-point Likert-type scale 6-item questionnaire, considering the following parameters: ease of use, anatomy comprehension compared with 2D radiological imaging, explanation of anatomical variations, explanation of surgical procedures, preoperative planning, and experience of gastrointestinal/neurological disorders. Results in the 3 groups were statistically compared using analysis of variance. Results. Using cross-sectional medical imaging, the developed VRE allowed to visualize a 3D patient-specific abdominal scene in 1 hour. Overall, the 6 items were evaluated positively by all groups; only anatomy comprehension was statistically significant different among the 3 groups. Conclusions. Our approach, based on open-source software and mobile hardware, proved to be a valid and well-appreciated system to visualize 3D patient-specific models, paving the way for a potential new tool for teaching and preoperative planning.},
	language = {en},
	number = {3},
	urldate = {2021-06-01},
	journal = {Surgical Innovation},
	author = {Vertemati, Maurizio and Cassin, Simone and Rizzetto, Francesco and Vanzulli, Angelo and Elli, Marco and Sampogna, Gianluca and Gallieni, Maurizio},
	month = jun,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {anatomy, head-mounted display, mobile, training, virtual reality},
	pages = {359--370},
	file = {SAGE PDF Full Text:/home/tei/Zotero/storage/8NA4Y7TR/Vertemati et al. - 2019 - A Virtual Reality Environment to Visualize Three-D.pdf:application/pdf},
}

@article{vinje_mini_nodate,
	title = {Mini invasiv behandling av brudd i hælbeinet ved hjelp av {3D} printing},
	shorttitle = {3dp for brudd i hæl},
	author = {Vinje, Tarjei},
	pages = {22},
	file = {Vinje - Mini invasiv behandling av brudd i hælbeinet ved h.pdf:/home/tei/Zotero/storage/NYXGDKQQ/Vinje - Mini invasiv behandling av brudd i hælbeinet ved h.pdf:application/pdf},
}

@article{chheang_collaborative_2021,
	title = {A collaborative virtual reality environment for liver surgery planning},
	volume = {99},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849321001400},
	doi = {10.1016/j.cag.2021.07.009},
	abstract = {Surgical planning software is a key component in the treatment of tumor diseases. However, desktop-based systems provide only limited visualization and interaction opportunities. Moreover, collaborative planning among members of a surgical team is only possible to a limited extent. In this work, a collaborative virtual reality (VR) environment to assist liver surgeons in tumor surgery planning is presented. Our aim is to improve virtual resection planning between surgeons in a remote or co-located environment. The system allows surgeons to define and adjust virtual resections on patient-specific organ 3D surfaces and 2D image slices. Changes on both modalities are synchronized, which will enable surgeons to iterate and refine the resection surfaces quickly. In addition, a real-time risk map visualization is presented that displays safety margins around tumors. An evaluation performed by liver surgeons provides information on potential benefits, such as the possibility to visualize complex cases and assessing the safety-critical areas, applicability, and limitations for further improvement.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Computers \& Graphics},
	author = {Chheang, Vuthea and Saalfeld, Patrick and Joeres, Fabian and Boedecker, Christian and Huber, Tobias and Huettl, Florentine and Lang, Hauke and Preim, Bernhard and Hansen, Christian},
	month = oct,
	year = {2021},
	keywords = {Human-computer interaction, Medical visualization, Surgical planning, Virtual reality},
	pages = {234--246},
	file = {ScienceDirect Full Text PDF:/home/tei/Zotero/storage/ABM86REF/Chheang et al. - 2021 - A collaborative virtual reality environment for li.pdf:application/pdf;ScienceDirect Snapshot:/home/tei/Zotero/storage/HTT3YQXH/S0097849321001400.html:text/html},
}

@misc{materialise_medical_nodate,
	title = {Medical {3D} {Printing} {\textbar} {3D} {Printing} {In} {Medical} {Field} {\textbar} {Materialise} {Medical}},
	url = {https://www.materialise.com/en/medical},
	abstract = {Premium medical 3D Printing and planning solutions. Complete 3D medical software \& services for healthcare professionals, engineers \& researchers. Better fitting implants, planning advanced clinical procedures; medical image-based planning and medical 3D printing technology is solving the most complex challenges.},
	language = {en},
	urldate = {2021-09-01},
	author = {materialise},
	file = {Snapshot:/home/tei/Zotero/storage/WPXIFYC3/medical.html:text/html},
}

@misc{dicomdirectorcom_surgeons_nodate,
	title = {Surgeons {\textbar} {Solutions} {For} {DICOM} {Done} {Better}, {Faster} + {3D} on every device},
	url = {https://www.dicomdirector.com/for-surgeons/},
	abstract = {DICOM Solution For Surgeons Viewable on Augmented, Virtual Reality devices, or on any Device. Better Surgical Planning, patient prep and more},
	language = {en-US},
	urldate = {2021-09-01},
	journal = {DICOM Director},
	author = {dicomdirector.com},
	file = {Snapshot:/home/tei/Zotero/storage/2WJMN8JV/for-surgeons.html:text/html},
}

@misc{medical_holodeck_medicalholodeck_nodate,
	title = {Medicalholodeck. {The} {Virtual} {Reality} {Platform} for {Medical} {Teamwork}.},
	url = {https://www.medicalholodeck.com/en/},
	abstract = {DICOM Viewer, human anatomy lab and 3D anatomy models for teamwork in virtual reality (VR).},
	language = {en},
	urldate = {2021-09-01},
	author = {Medical Holodeck},
	file = {Snapshot:/home/tei/Zotero/storage/I8M2GC3Z/en.html:text/html},
}

@article{chen_efficacy_2019,
	title = {The efficacy of using {3D} printing models in the treatment of fractures: a randomised clinical trial},
	volume = {20},
	issn = {1471-2474},
	shorttitle = {The efficacy of using {3D} printing models in the treatment of fractures},
	url = {https://doi.org/10.1186/s12891-019-2448-9},
	doi = {10.1186/s12891-019-2448-9},
	abstract = {The aim of this study was to evaluate the efficacy of the use of three-dimensional (3D) printing models for preoperative planning in cases of complex fracture.},
	language = {en},
	number = {1},
	urldate = {2021-09-24},
	journal = {BMC Musculoskeletal Disorders},
	author = {Chen, Chunhui and Cai, Leyi and Zheng, Wenhao and Wang, Jianshun and Guo, Xiaoshan and Chen, Hua},
	month = feb,
	year = {2019},
	pages = {65},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/XEW9GCF5/Chen et al. - 2019 - The efficacy of using 3D printing models in the tr.pdf:application/pdf},
}

@misc{noauthor_visualizing_2017,
	title = {Visualizing {MRI} \& {CT} {Scans} in {Mixed} {Reality} / {VR} / {AR}, {Part} 1: {Importing} {Data}},
	shorttitle = {Visualizing {MRI} \& {CT} {Scans} in {Mixed} {Reality} / {VR} / {AR}, {Part} 1},
	url = {https://www.andreasjakl.com/visualising-mri-ct-scans-in-mixed-reality-vr-ar-part-1-importing-data/},
	abstract = {First part in a step-by-step series to visualize MRI / CT / ultrasound data in 3D using HoloLens and Google ARCore.},
	language = {en-US},
	urldate = {2021-09-27},
	journal = {andreasjakl.com},
	month = oct,
	year = {2017},
	file = {Snapshot:/home/tei/Zotero/storage/FZ5MJC6G/visualising-mri-ct-scans-in-mixed-reality-vr-ar-part-1-importing-data.html:text/html},
}

@techreport{ceevra_inc_using_2019,
	type = {Clinical trial registration},
	title = {Using {Virtual} {Reality} ({VR}) {Models} for {Preoperative} {Planning}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03334344},
	abstract = {A prospective, randomized, controlled study designed to assess whether digital virtual reality (VR) models, created from existing CT scans and MRIs, provide surgeons with an improved understanding of their patients' anatomy, resulting in more efficient operations (robotic partial nephrectomy) and improved patient care.},
	number = {NCT03334344},
	urldate = {2021-09-26},
	institution = {clinicaltrials.gov},
	author = {{Ceevra, Inc.}},
	month = jun,
	year = {2019},
	note = {submitted: November 1, 2017},
}

@misc{noauthor_ceevra_nodate,
	title = {Ceevra {\textbar} {Advanced} {3D} {Visualization} for {Surgeons}},
	url = {https://ceevra.com/},
	language = {en-US},
	urldate = {2021-09-27},
	file = {Snapshot:/home/tei/Zotero/storage/9YFQ2EK9/ceevra.com.html:text/html},
}

@techreport{ceevra_inc_using_2019-1,
	type = {Clinical trial registration},
	title = {Using {Virtual} {Reality} ({VR}) {Models} for {Preoperative} {Planning}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03334344},
	abstract = {A prospective, randomized, controlled study designed to assess whether digital virtual reality (VR) models, created from existing CT scans and MRIs, provide surgeons with an improved understanding of their patients' anatomy, resulting in more efficient operations (robotic partial nephrectomy) and improved patient care.},
	number = {NCT03334344},
	urldate = {2021-10-03},
	institution = {clinicaltrials.gov},
	author = {{Ceevra, Inc.}},
	month = jun,
	year = {2019},
	note = {submitted: November 1, 2017},
}

@article{shirk_effect_2019,
	title = {Effect of 3-{Dimensional} {Virtual} {Reality} {Models} for {Surgical} {Planning} of {Robotic}-{Assisted} {Partial} {Nephrectomy} on {Surgical} {Outcomes}: {A} {Randomized} {Clinical} {Trial}},
	volume = {2},
	issn = {2574-3805},
	shorttitle = {Effect of 3-{Dimensional} {Virtual} {Reality} {Models} for {Surgical} {Planning} of {Robotic}-{Assisted} {Partial} {Nephrectomy} on {Surgical} {Outcomes}},
	doi = {10.1001/jamanetworkopen.2019.11598},
	abstract = {Importance: Planning complex operations such as robotic-assisted partial nephrectomy requires surgeons to review 2-dimensional computed tomography or magnetic resonance images to understand 3-dimensional (3-D), patient-specific anatomy.
Objective: To determine surgical outcomes for robotic-assisted partial nephrectomy when surgeons reviewed 3-D virtual reality (VR) models during operative planning.
Design, Setting, and Participants: A single-blind randomized clinical trial was performed. Ninety-two patients undergoing robotic-assisted partial nephrectomy performed by 1 of 11 surgeons at 6 large teaching hospitals were prospectively enrolled and randomized. Enrollment and data collection occurred from October 2017 through December 2018, and data analysis was performed from December 2018 through March 2019.
Interventions: Patients were assigned to either a control group undergoing usual preoperative planning with computed tomography and/or magnetic resonance imaging only or an intervention group where imaging was supplemented with a 3-D VR model. This model was viewed on the surgeon's smartphone in regular 3-D format and in VR using a VR headset.
Main Outcomes and Measures: The primary outcome measure was operative time. It was hypothesized that the operations performed using the 3-D VR models would have shorter operative time than those performed without the models. Secondary outcomes included clamp time, estimated blood loss, and length of hospital stay.
Results: Ninety-two patients (58 men [63\%]) with a mean (SD) age of 60.9 (11.6) years were analyzed. The analysis included 48 patients randomized to the control group and 44 randomized to the intervention group. When controlling for case complexity and other covariates, patients whose surgical planning involved 3-D VR models showed differences in operative time (odds ratio [OR], 1.00; 95\% CI, 0.37-2.70; estimated OR, 2.47), estimated blood loss (OR, 1.98; 95\% CI, 1.04-3.78; estimated OR, 4.56), clamp time (OR, 1.60; 95\% CI, 0.79-3.23; estimated OR, 11.22), and length of hospital stay (OR, 2.86; 95\% CI, 1.59-5.14; estimated OR, 5.43). Estimated ORs were calculated using the parameter estimates from the generalized estimating equation model. Referent group values for each covariate and the corresponding nephrometry score were summed across the covariates and nephrometry score, and the sum was exponentiated to obtain the OR. A mean of the estimated OR weighted by sample size for each nephrometry score strata was then calculated.
Conclusions and Relevance: This large, randomized clinical trial demonstrated that patients whose surgical planning involved 3-D VR models had reduced operative time, estimated blood loss, clamp time, and length of hospital stay.
Trial Registration: ClinicalTrials.gov identifiers (1 registration per site): NCT03334344, NCT03421418, NCT03534206, NCT03542565, NCT03556943, and NCT03666104.},
	language = {eng},
	number = {9},
	journal = {JAMA network open},
	author = {Shirk, Joseph D. and Thiel, David D. and Wallen, Eric M. and Linehan, Jennifer M. and White, Wesley M. and Badani, Ketan K. and Porter, James R.},
	month = sep,
	year = {2019},
	pmid = {31532520},
	pmcid = {PMC6751754},
	keywords = {Humans, Male, Operative Time, Virtual Reality, Blood Loss, Surgical, Computer Simulation, Female, Glomerular Filtration Rate, Imaging, Three-Dimensional, Length of Stay, Middle Aged, Nephrectomy, Robotic Surgical Procedures, Single-Blind Method},
	pages = {e1911598},
	file = {Full Text:/home/tei/Zotero/storage/CUFZZM48/Shirk et al. - 2019 - Effect of 3-Dimensional Virtual Reality Models for.pdf:application/pdf},
}

@article{brouwers_what_2020,
	title = {What is the value of {3D} virtual reality in understanding acetabular fractures?},
	volume = {30},
	issn = {1633-8065},
	doi = {10.1007/s00590-019-02537-w},
	abstract = {BACKGROUND: Acetabular fractures are difficult to classify owing to the complex three-dimensional (3D) anatomy of the pelvis. 3D printing helps to understand and reliably classify acetabular fracture types. 3D-virtual reality (VR) may have comparable benefits. Our hypothesis is that 3D-VR is equivalent to 3D printing in understanding acetabular fracture patterns.
METHODS: A total of 27 observers of various experience levels from several hospitals were requested to classify twenty 3D printed and VR models according to the Judet-Letournel classification. Additionally, surgeons were asked to state their preferred surgical approach and patient positioning. Time to classify each fracture type was recorded. The cases were randomized to rule out a learning curve. Inter-observer agreement was analyzed using Fleiss' kappa statistics (κ).
RESULTS: Inter-observer agreements varied by observer group and type of model used to classify the fracture: medical students: 3D print (κ = 0.61), VR (κ = 0.41); junior surgical residents: 3D print (0.51) VR (0.54); senior surgical residents: 3D print (0.66) VR (0.52); junior surgeons: 3D print (0.56), VR (0.43); senior surgeons: 3D print (κ = 0.59), VR (κ = 0.42). Using 3D printed models, there was more agreement on the surgical approach (junior surgeons κ = 0.23, senior surgeons κ = 0.31) when compared with VR (junior surgeons κ = 0.17, senior surgeons 0.25). No difference was found in time used to classify these fractures between 3D printing and VR for all groups (P = 1.000).
CONCLUSIONS: The Judet-Letournel acetabular classification stays difficult to interpret; only moderate kappa agreements were found. We found 3D-VR inferior to 3D printing in classifying acetabular fractures. Furthermore, the current 3D-VR technology is still not practical for intra-operative use.},
	language = {eng},
	number = {1},
	journal = {European Journal of Orthopaedic Surgery \& Traumatology: Orthopedie Traumatologie},
	author = {Brouwers, Lars and Pull Ter Gunne, Albert F. and de Jongh, Mariska A. and Maal, Thomas J. J. and Vreeken, Rinaldo and van der Heijden, Frank H. W. M. and Leenen, Luke P. H. and Spanjersberg, Willem R. and van Helden, Sven H. and Verbeek, Diederik O. and Bemelman, Mike and Lansink, Koen W. W.},
	month = jan,
	year = {2020},
	pmid = {31531739},
	keywords = {Adult, Fractures, Bone, Humans, Male, Printing, Three-Dimensional, Tomography, X-Ray Computed, Virtual Reality, Virtual reality, Female, 3D printing, Acetabular surgery, Acetabulum, Clinical Competence, Comprehension, Education, Medical, Graduate, Fracture Fixation, Internal, Inter-observer, Internship and Residency, Judet–Letournel classification, Learning Curve, Netherlands, Observer Variation, Orthopedics, Registries},
	pages = {109--116},
}

@book{mihelj_virtual_2014,
	address = {Dordrecht},
	series = {Intelligent {Systems}, {Control} and {Automation}: {Science} and {Engineering}},
	title = {Virtual {Reality} {Technology} and {Applications}},
	volume = {68},
	isbn = {978-94-007-6909-0 978-94-007-6910-6},
	url = {http://link.springer.com/10.1007/978-94-007-6910-6},
	language = {en},
	urldate = {2021-11-03},
	publisher = {Springer Netherlands},
	author = {Mihelj, Matjaž and Novak, Domen and Beguš, Samo},
	year = {2014},
	doi = {10.1007/978-94-007-6910-6},
	file = {Mihelj et al. - 2014 - Virtual Reality Technology and Applications.pdf:/home/tei/Zotero/storage/UXRZDJV5/Mihelj et al. - 2014 - Virtual Reality Technology and Applications.pdf:application/pdf},
}

@misc{noauthor_feelreal_nodate,
	title = {{FEELREAL} {Multisensory} {VR} {Mask}},
	url = {https://feelreal.com/},
	abstract = {Feelreal is the world’s first Multisensory Mask that releases smells, vibrates, and blasts your face with air or mist to make VR experiences even more immersing.},
	language = {en},
	urldate = {2021-11-03},
	file = {Snapshot:/home/tei/Zotero/storage/RH69TX6I/feelreal.com.html:text/html},
}

@misc{noauthor_oculus_nodate,
	title = {Oculus {Quest} 2: {Our} {Most} {Advanced} {New} {All}-in-{One} {VR} {Headset} {\textbar} {Oculus}},
	shorttitle = {Oculus {Quest} 2},
	url = {https://www.oculus.com/quest-2/},
	abstract = {Oculus Quest 2 is our newest, most advanced all-in-one VR system yet. Explore an expansive library of awe-inspiring games and immersive experiences with unparalleled freedom.},
	language = {en},
	urldate = {2021-11-03},
	file = {Snapshot:/home/tei/Zotero/storage/76WWZLCL/quest-2.html:text/html},
}

@article{hackett_three-dimensional_2016,
	title = {Three-{Dimensional} {Display} {Technologies} for {Anatomical} {Education}: {A} {Literature} {Review}},
	volume = {25},
	issn = {1573-1839},
	shorttitle = {Three-{Dimensional} {Display} {Technologies} for {Anatomical} {Education}},
	url = {https://doi.org/10.1007/s10956-016-9619-3},
	doi = {10.1007/s10956-016-9619-3},
	abstract = {Anatomy is a foundational component of biological sciences and medical education and is important for a variety of clinical tasks. To augment current curriculum and improve students’ spatial knowledge of anatomy, many educators, anatomists, and researchers use three-dimensional (3D) visualization technologies. This article reviews 3D display technologies and their associated assessments for anatomical education. In the first segment, the review covers the general function of displays employing 3D techniques. The second segment of the review highlights the use and assessment of 3D technology in anatomical education, focusing on factors such as knowledge gains, student perceptions, and cognitive load. The review found 32 articles on the use of 3D displays in anatomical education and another 38 articles on the assessment of 3D displays. The review shows that the majority (74 \%) of studies indicate that the use of 3D is beneficial for many tasks in anatomical education, and that student perceptions are positive toward the technology.},
	language = {en},
	number = {4},
	urldate = {2021-11-03},
	journal = {Journal of Science Education and Technology},
	author = {Hackett, Matthew and Proctor, Michael},
	month = aug,
	year = {2016},
	pages = {641--654},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/JS4CY7MQ/Hackett and Proctor - 2016 - Three-Dimensional Display Technologies for Anatomi.pdf:application/pdf},
}

@article{kooi_visual_2004,
	title = {Visual comfort of binocular and {3D} displays},
	volume = {25},
	issn = {0141-9382},
	url = {https://www.sciencedirect.com/science/article/pii/S0141938204000502},
	doi = {10.1016/j.displa.2004.07.004},
	abstract = {Imperfections in binocular image pairs can cause serious viewing discomfort. For example, in stereo vision systems eye strain is caused by unintentional mismatches between the left and right eye images (stereo imperfections). Head-mounted displays can induce eye strain due to optical misalignments. We have experimentally determined the level of (dis)comfort experienced by human observers viewing brief presentations of imperfect binocular image pairs. We used a wide range of binocular image imperfections that are representative for commonly encountered optical errors (spatial distortions: shifts, magnification, rotation, keystone), imperfect filters (photometric asymmetries: luminance, color, contrast, crosstalk), and stereoscopic disparities. The results show that nearly all binocular image asymmetries seriously reduce visual comfort if present in a large enough amount. From our data we estimate threshold values for the onset of discomfort. The database collected in this study allows a more accurate prediction of visual comfort from the specification of a given binocular viewing system. Being able to predict the level of visual discomfort from the specification of binocular viewing systems greatly helps the design and selection process. This paper provides the basis.},
	language = {en},
	number = {2},
	urldate = {2021-11-03},
	journal = {Displays},
	author = {Kooi, Frank L. and Toet, Alexander},
	month = aug,
	year = {2004},
	keywords = {3D displays, Binocular asymmetry, Binocular crosstalk, Binocular distortions, Stereoscopic vision, Visual comfort},
	pages = {99--108},
	file = {ScienceDirect Snapshot:/home/tei/Zotero/storage/ZUWPGSJG/S0141938204000502.html:text/html},
}

@article{bradley_history_2008,
	title = {History of {Medical} {Imaging}},
	volume = {152},
	journal = {Proceedings of the American Philosophical Society},
	author = {Bradley, William},
	month = sep,
	year = {2008},
	pages = {349--61},
	file = {Full Text PDF:/home/tei/Zotero/storage/37G2IPAH/Bradley - 2008 - History of Medical Imaging.pdf:application/pdf},
}

@article{king_vr_1993,
	title = {{VR} use in education},
	volume = {7},
	issn = {0922-6567, 1573-0573},
	url = {http://link.springer.com/10.1007/BF00398472},
	doi = {10.1007/BF00398472},
	abstract = {Since the first time the term "Virtual Reality" (VR) has been used back in the 60s, VR has evolved in different manners becoming more and more similar to the real world. Two different kinds of VR can be identified: non-immersive and immersive. The former is a computer-based environment that can simulate places in the real or imagined worlds; the latter takes the idea even further by giving the perception of being physically present in the non-physical world. While non-immersive VR can be based on a standard computer, immersive VR is still evolving as the needed devices are becoming more user friendly and economically accessible. In the past, there was a major difficulty about using equipment such as a helmet with goggles, while now new devices are being developed to make usability better for the user. VR, which is based on three basic principles: Immersion, Interaction, and User involvement with the environment and narrative, offers a very high potential in education by making learning more motivating and engaging. Up to now, the use of immersive-VR in educational games has been limited due to high prices of the devices and their limited usability. Now new tools like the commercial "Oculus Rift", make it possible to access immersive-VR in lots of educational situations. This paper reports a survey on the scientific literature on the advantages and potentials in the use of Immersive Virtual Reality in Education in the last two years (2013-14). It shows how VR in general, and immersive VR in particular, has been used mostly for adult training in special situations or for university students. It then focuses on the possible advantages and drawbacks of its use in education with reference to different classes of users like children and some kinds of cognitive disabilities (with particular reference to the Down syndrome). It concludes outlining strategies that could be carried out to verify these ideas.},
	language = {en},
	number = {4},
	urldate = {2021-11-11},
	journal = {Machine Translation},
	author = {King, Margaret},
	year = {1993},
	pages = {273--279},
	file = {King - 1993 - State of the art and perspectives.pdf:/home/tei/Zotero/storage/XJ6CXJD3/King - 1993 - State of the art and perspectives.pdf:application/pdf},
}

@inproceedings{freina_immersive_2015,
	address = {Bucharest, Romania},
	title = {Immersive {Virtual} {Reality} in {Education}: {State} of the {Art} and {Perspectives}},
	volume = {1},
	copyright = {Copyright "Carol I" National Defence University 2015},
	shorttitle = {A {Literature} {Review} on {Immersive} {Virtual} {Reality} in {Education}},
	url = {https://www.proquest.com/docview/1681252932/abstract/D4B2F610BED4D5BPQ/1},
	abstract = {Since the first time the term "Virtual Reality" (VR) has been used back in the 60s, VR has evolved in different manners becoming more and more similar to the real world. Two different kinds of VR can be identified: non-immersive and immersive. The former is a computer-based environment that can simulate places in the real or imagined worlds; the latter takes the idea even further by giving the perception of being physically present in the non-physical world. While non-immersive VR can be based on a standard computer, immersive VR is still evolving as the needed devices are becoming more user friendly and economically accessible. In the past, there was a major difficulty about using equipment such as a helmet with goggles, while now new devices are being developed to make usability better for the user. VR, which is based on three basic principles: Immersion, Interaction, and User involvement with the environment and narrative, offers a very high potential in education by making learning more motivating and engaging. Up to now, the use of immersive-VR in educational games has been limited due to high prices of the devices and their limited usability. Now new tools like the commercial "Oculus Rift", make it possible to access immersive-VR in lots of educational situations. This paper reports a survey on the scientific literature on the advantages and potentials in the use of Immersive Virtual Reality in Education in the last two years (2013-2014). It shows how VR in general, and immersive VR in particular, has been used mostly for adult training in special situations or for university students. It then focuses on the possible advantages and drawbacks of its use in education with reference to different classes of users like children and some kinds of cognitive disabilities (with particular reference to the Down syndrome). It concludes outlining strategies that could be carried out to verify these ideas.},
	language = {English},
	urldate = {2021-11-11},
	booktitle = {The {International} {Scientific} {Conference} {eLearning} and {Software} for {Education}},
	publisher = {"Carol I" National Defence University},
	author = {Freina, Laura and Ott, Michela},
	year = {2015},
	note = {Num Pages: 9},
	keywords = {Virtual reality, Cognitive style, Education, Education--Computer Applications, Experiments, Handicapped accessibility, Literature reviews},
	pages = {133--141},
	file = {Full Text PDF:/home/tei/Zotero/storage/W8BVMB96/Freina and Ott - 2015 - A Literature Review on Immersive Virtual Reality i.pdf:application/pdf},
}

@article{merhi_motion_2007,
	title = {Motion {Sickness}, {Console} {Video} {Games}, and {Head}-{Mounted} {Displays}},
	volume = {49},
	issn = {0018-7208, 1547-8181},
	url = {http://journals.sagepub.com/doi/10.1518/001872007X230262},
	doi = {10.1518/001872007X230262},
	abstract = {Objective: We evaluated the nauseogenic properties of commercial console video games (i.e., games that are sold to the public) when presented through a head-mounted display. Background: Anecdotal reports suggest that motion sickness may occur among players of contemporary commercial console video games. Methods: Participants played standard console video games using an Xbox game system. We varied the participants' posture (standing vs. sitting) and the game (two Xbox games). Participants played for up to 50 min and were asked to discontinue if they experienced any symptoms of motion sickness. Results: Sickness occurred in all conditions, but it was more common during standing. During seated play there were significant differences in head motion between sick and well participants before the onset of motion sickness. Conclusion: The results indicate that commercial console video game systems can induce motion sickness when presented via a head-mounted display and support the hypothesis that motion sickness is preceded by instability in the control of seated posture. Application: Potential applications of this research include changes in the design of console video games and recommendations for how such systems should be used.},
	language = {en},
	number = {5},
	urldate = {2021-11-11},
	journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
	author = {Merhi, Omar and Faugloire, Elise and Flanagan, Moira and Stoffregen, Thomas A.},
	month = oct,
	year = {2007},
	pages = {920--934},
	file = {Merhi et al. - 2007 - Motion Sickness, Console Video Games, and Head-Mou.pdf:/home/tei/Zotero/storage/R7WEBVK8/Merhi et al. - 2007 - Motion Sickness, Console Video Games, and Head-Mou.pdf:application/pdf},
}

@misc{lang_introduction_2013,
	title = {An {Introduction} to {Positional} {Tracking} and {Degrees} of {Freedom} ({DOF})},
	url = {https://www.roadtovr.com/introduction-positional-tracking-degrees-freedom-dof/},
	abstract = {Positional tracking and degrees of freedom are important concepts needed for understanding how people interact in virtual reality games and other VR spaces.},
	language = {en-US},
	urldate = {2021-11-11},
	journal = {Road to VR},
	author = {Lang, Ben},
	month = feb,
	year = {2013},
	note = {Section: Body Tracking},
	file = {Snapshot:/home/tei/Zotero/storage/Y8UE9GUV/introduction-positional-tracking-degrees-freedom-dof.html:text/html},
}

@article{chang_virtual_2020,
	title = {Virtual {Reality} {Sickness}: {A} {Review} of {Causes} and {Measurements}},
	volume = {36},
	issn = {1044-7318},
	shorttitle = {Virtual {Reality} {Sickness}},
	url = {https://doi.org/10.1080/10447318.2020.1778351},
	doi = {10.1080/10447318.2020.1778351},
	abstract = {In virtual reality (VR), users can experience symptoms of motion sickness, which is referred to as VR sickness or cybersickness. The symptoms include but are not limited to eye fatigue, disorientation, and nausea, which can impair the VR experience of users. Though many studies have attempted to reduce the discomfort, they produced conflicting results with varying degrees of VR sickness. In particular, a visually improved VR does not necessarily result in decreased VR sickness. To understand these unexpected results, we surveyed the causes of VR sickness and measurement of symptoms. We reorganized the causes of the VR sickness into three major factors (hardware, content, and human factors) and investigated the sub-component of each factor. We then surveyed frequently used measures of VR sickness, both subjective and objective approaches. We also investigated emerging approaches for reducing VR sickness and proposed a multimodal fidelity hypothesis to give an insight into future studies.},
	number = {17},
	urldate = {2021-11-15},
	journal = {International Journal of Human–Computer Interaction},
	author = {Chang, Eunhee and Kim, Hyun Taek and Yoo, Byounghyun},
	month = oct,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447318.2020.1778351},
	pages = {1658--1682},
	file = {Full Text PDF:/home/tei/Zotero/storage/TNW56XLB/Chang et al. - 2020 - Virtual Reality Sickness A Review of Causes and M.pdf:application/pdf;Snapshot:/home/tei/Zotero/storage/8JF5HB3H/10447318.2020.html:text/html},
}

@misc{noauthor_use_2021,
	title = {The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation: a scoping review},
	author = {, Sang-Hee Park2, Todd P. Chang3, Timothy Jung4 {and} Ralph MacKinnon1, Katherine Kuyt1},
	year = {2021},
}

@article{kuyt_use_2021,
	title = {The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation: a scoping review},
	volume = {6},
	issn = {2059-0628},
	shorttitle = {The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation},
	url = {https://doi.org/10.1186/s41077-021-00158-0},
	doi = {10.1186/s41077-021-00158-0},
	abstract = {Virtual reality (VR) and augmented reality (AR) have been proposed as novel methods to enhance cardio-pulmonary resuscitation (CPR) performance and increase engagement with CPR training. A scoping review was conducted to map the global evolution of these new approaches to CPR training, to assess their efficacy and determine future directions to meet gaps in current knowledge.},
	number = {1},
	urldate = {2021-11-15},
	journal = {Advances in Simulation},
	author = {Kuyt, Katherine and Park, Sang-Hee and Chang, Todd P. and Jung, Timothy and MacKinnon, Ralph},
	month = apr,
	year = {2021},
	keywords = {Virtual reality, Augmented reality, Cardiopulmonary resuscitation, Simulation},
	pages = {11},
	file = {Full Text PDF:/home/tei/Zotero/storage/5EED2F7U/Kuyt et al. - 2021 - The use of virtual reality and augmented reality t.pdf:application/pdf;Snapshot:/home/tei/Zotero/storage/BC2IJARK/s41077-021-00158-0.html:text/html},
}

@misc{noauthor_notitle_nodate,
	file = {_.pdf:/home/tei/Zotero/storage/6CY64R2N/_.pdf:application/pdf},
}

@book{swiontkowski_manual_2013,
	address = {Philadelphia},
	edition = {7th ed},
	title = {Manual of orthopaedics},
	isbn = {978-1-4511-1592-5},
	publisher = {Wolters Kluwer/Lippincott Williams \& Wilkins Health},
	editor = {Swiontkowski, Marc F. and Stovitz, Steven D.},
	year = {2013},
	keywords = {Fractures, Bone, Orthopedics, Handbooks, injuries, methods, Musculoskeletal System, rehabilitation},
}

@article{napolitano_challenging_2010,
	title = {Challenging {Issues} in {Surgical} {Critical} {Care}, {Trauma}, and {Acute} {Care} {Surgery}: {A} {Report} {From} the {Critical} {Care} {Committee} of the {American} {Association} for the {Surgery} of {Trauma}},
	volume = {69},
	issn = {2163-0755},
	shorttitle = {Challenging {Issues} in {Surgical} {Critical} {Care}, {Trauma}, and {Acute} {Care} {Surgery}},
	url = {https://journals.lww.com/jtrauma/FullText/2010/12000/Challenging_Issues_in_Surgical_Critical_Care,.48.aspx},
	doi = {10.1097/TA.0b013e3182011089},
	abstract = {Critical care workforce analyses estimate a 35\% shortage of intensivists by 2020 as a result of the aging population and the growing demand for greater utilization of intensivists. Surgical critical care in the U.S. is particularly challenged by a significant shortfall of surgical intensivists, with only 2586 surgeons currently certified in surgical critical care by the American Board of Surgery, and even fewer surgeons (1204) recertified in surgical critical care as of 2009. Surgical critical care fellows (160 in 2009) represent only 7.6\% of all critical care trainees (2109 in 2009), with the largest number of critical care fellowship positions in internal medicine (1472, 69.8\%). Traditional trauma fellowships have now transitioned into Surgical Critical Care or Acute Care Surgery (trauma, surgical critical care, emergency surgery) fellowships. Since adult critical care services are a large, expensive part of U.S. healthcare and workforce shortages continue to impact our healthcare system, recommendations for regionalization of critical care services in the U.S. is considered. The Critical Care Committee of the AAST has compiled national data regarding these important issues that face us in surgical critical care, trauma and acute care surgery, and discuss potential solutions for these issues.},
	language = {en-US},
	number = {6},
	urldate = {2021-11-27},
	journal = {Journal of Trauma and Acute Care Surgery},
	author = {Napolitano, Lena M. and Fulda, Gerard J. and Davis, Kimberly A. and Ashley, Dennis W. and Friese, Randall and Van Way, Charles W. III and Meredith, J. Wayne and Fabian, Timothy C. and Jurkovich, Gregory J. and Peitzman, Andrew B.},
	month = dec,
	year = {2010},
	pages = {1619--1633},
	file = {Snapshot:/home/tei/Zotero/storage/KS47CB8V/Challenging_Issues_in_Surgical_Critical_Care,.48.html:text/html},
}

@article{chougule_conversions_2013,
	title = {Conversions of {CT} {Scan} {Images} into 3 {D} {Point} {Cloud} {Data} for the {Development} of 3 {D} {Solid} {Model} using {B}-{Rep} {Scheme}},
	url = {https://www.semanticscholar.org/paper/Conversions-of-CT-Scan-Images-into-3-D-Point-Cloud-Chougule-Mulay/d4875163b4162ba44843a326490f20d6c7fa33e7},
	abstract = {This paper deals with generation of B-spline curves from non-invasive medical images viz. This paper deals with generation of B-spline curves from non-invasive medical images viz. CT / MRI scans. The volumetric data i.e. voxel and triangular facet triangle based models are primarily used for bio-modeling and visualization, which requires huge memory space. On the other side, recent advances in CAD technology facilitate design, prototyping and manufacturing of any object having freeform surfaces. These CAD-based solid modeling is based on boundary representation (B-rep) techniques. Image Processing techniques are proposed to extract point cloud data from stalk of CT scan images. These points are further preprocessed for sorting, smoothening and B spline curve fitting. This method facilitates the construction of the model by minimizing the size of the files and ensuring the closure of bounding surfaces.},
	language = {en},
	urldate = {2021-12-01},
	journal = {undefined},
	author = {Chougule and Mulay and Ahuja, N.},
	year = {2013},
	file = {Snapshot:/home/tei/Zotero/storage/CRBBEDUT/d4875163b4162ba44843a326490f20d6c7fa33e7.html:text/html},
}

@inproceedings{chougule_conversions_2013-1,
	title = {Conversions of {CT} {Scan} {Images} into {3D} {Point} {Cloud} {Data} for the {Development} of {3D} {Solid} {Model} using {B}-{Rep} {Scheme}},
	abstract = {This paper deals with generation of B-spline curves from non-invasive medical images viz. CT / MRI scans. The volumetric data i.e. voxel and triangular facet triangle based models are primarily used for bio-modeling and visualization, which requires huge memory space. On the other side, recent advances in CAD technology facilitate design, prototyping and manufacturing of any object having freeform surfaces. These CAD-based solid modeling is based on boundary representation (B-rep) techniques. Image Processing techniques are proposed to extract point cloud data from stalk of CT scan images. These points are further preprocessed for sorting, smoothening and B spline curve fitting. This method facilitates the construction of the model by minimizing the size of the files and ensuring the closure of bounding surfaces.},
	author = {Chougule, Vikas and Mulay, Arati and Ahuja, B.},
	month = dec,
	year = {2013},
	file = {Full Text PDF:/home/tei/Zotero/storage/XZRHE5CB/Chougule et al. - 2013 - Conversions of CT Scan Images into 3D Point Cloud .pdf:application/pdf},
}

@incollection{zhang_1_2008,
	address = {Burlington},
	series = {Biomedical {Engineering}},
	title = {1 - {Medical} {Imaging}},
	isbn = {978-0-12-373583-6},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123735836500050},
	abstract = {Medical imaging forms a key part of clinical diagnosis, and improvements in the quality and type of information available from such images have extended the diagnostic accuracy and range of new applications in health care. Medical imaging plays an important role in neurology, cardiology, and cancer centers. This chapter provides a brief overview of the basic physics, instrumentation, and clinical applications of each imaging modality and recent technological advances. Planar X-ray imaging is used for diagnosing bone breaks, lung disease, a number of gastrointestinal (GI) diseases (fluoroscopy), and conditions of the genitourinary tract, such as kidney stones. In contrast to X-ray, ultrasound, and MRI, nuclear medicine imaging techniques do not produce an anatomical map of the body, but instead image the spatial distribution of radioactive materials that are introduced into the body. Ultrasound is non-ionizing, real-time, portable, and inexpensive compared with other clinical imaging modalities. Ultrasound is particularly functional for obstetrics and quantification of blood flow using Doppler measurements. The major uses of MRI are in the areas of brain disease, spinal disorders, angiography, cardiac assessment, and musculoskeletal damage. Diffuse Optical Imaging is characterized by its noninvasive nature, chemical specificity, and good temporal resolution. NIR methods are used in mammography and real-time monitoring of blood oxygenation levels of patients during medical procedures.},
	language = {en},
	urldate = {2021-12-01},
	booktitle = {Biomedical {Information} {Technology}},
	publisher = {Academic Press},
	author = {Zhang, Xiaofeng and Smith, Nadine and Webb, Andrew},
	editor = {Feng, David Dagan},
	month = jan,
	year = {2008},
	doi = {10.1016/B978-012373583-6.50005-0},
	pages = {3--27},
	file = {ScienceDirect Snapshot:/home/tei/Zotero/storage/IZV9885B/B9780123735836500050.html:text/html},
}

@book{suetens_fundamentals_2017,
	title = {Fundamentals of {Medical} {Imaging}},
	isbn = {978-1-107-15978-5},
	abstract = {This third edition provides a concise and generously illustrated survey of the complete field of medical imaging and image computing, explaining the mathematical and physical principles and giving the reader a clear understanding of how images are obtained and interpreted. Medical imaging and image computing are rapidly evolving fields, and this edition has been updated with the latest developments in the field, as well as new images and animations. An introductory chapter on digital image processing is followed by chapters on the imaging modalities: radiography, CT, MRI, nuclear medicine and ultrasound. Each chapter covers the basic physics and interaction with tissue, the image reconstruction process, image quality aspects, modern equipment, clinical applications, and biological effects and safety issues. Subsequent chapters review image computing and visualization for diagnosis and treatment. Engineers, physicists and clinicians at all levels will find this new edition an invaluable aid in understanding the principles of imaging and their clinical applications.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Suetens, Paul},
	month = may,
	year = {2017},
	note = {Google-Books-ID: U11EDgAAQBAJ},
	keywords = {Medical / Diagnostic Imaging / General, Medical / Radiology, Radiotherapy \& Nuclear Medicine},
}

@book{hamblen_outline_2010,
	edition = {14. edition},
	title = {outline of orthopaedics},
	author = {Hamblen, David L. and Simpson, A Hamish R.W.},
	year = {2010},
}

@article{fishman_volume_2006,
	title = {Volume {Rendering} versus {Maximum} {Intensity} {Projection} in {CT} {Angiography}: {What} {Works} {Best}, {When}, and {Why}},
	volume = {26},
	issn = {0271-5333},
	shorttitle = {Volume {Rendering} versus {Maximum} {Intensity} {Projection} in {CT} {Angiography}},
	url = {https://pubs.rsna.org/doi/10.1148/rg.263055186},
	doi = {10.1148/rg.263055186},
	abstract = {The introduction and widespread availability of 16-section multi–detector row computed tomographic (CT) technology and, more recently, 64-section scanners, has greatly advanced the role of CT angiography in clinical practice. CT angiography has become a key component of state-of-the-art imaging, with applications ranging from oncology (eg, staging of pancreatic or renal cancer) to classic vascular imaging (eg, evaluation of aortic aneurysms and renal artery stenoses) as well as newer techniques such as coronary artery imaging and peripheral runoff studies. With an average of 400–1000 images in each volume data set, three-dimensional postprocessing is crucial to volume visualization. Radiologists now have workstations that provide capabilities for evaluation of these data sets by using a range of software programs and processing tools. Although different systems have unique capabilities and functionality, all provide the options of volume rendering and maximum intensity projection for image display and analysis. These two postprocessing techniques have different advantages and disadvantages when used in clinical practice, and it is important that radiologists understand when and how each technique should be used.

© RSNA, 2006},
	number = {3},
	urldate = {2021-12-06},
	journal = {RadioGraphics},
	author = {Fishman, Elliot K. and Ney, Derek R. and Heath, David G. and Corl, Frank M. and Horton, Karen M. and Johnson, Pamela T.},
	month = may,
	year = {2006},
	note = {Publisher: Radiological Society of North America},
	pages = {905--922},
	file = {Full Text PDF:/home/tei/Zotero/storage/7PCVKPLZ/Fishman et al. - 2006 - Volume Rendering versus Maximum Intensity Projecti.pdf:application/pdf},
}

@misc{noauthor_dicom_nodate,
	title = {{DICOM}},
	url = {https://www.dicomstandard.org/},
	urldate = {2022-01-21},
	file = {DICOM:/home/tei/Zotero/storage/JSCFSF4J/www.dicomstandard.org.html:text/html},
}

@misc{noauthor_stl_2019,
	type = {web page},
	title = {{STL} ({STereoLithography}) {File} {Format} {Family}},
	copyright = {Text is U.S. government work},
	url = {https://www.loc.gov/preservation/digital/formats/fdd/fdd000504.shtml},
	abstract = {Format Description for STL\_family -- an openly documented plain text format for describing an object as a triangular mesh, i.e., as a representation of a 3-dimensional surface geometry in triangular facets. Each facet is described by a perpendicular (normal) direction and three points representing the vertices (corners) of the , triangle. The STL format was developed for stereolithography, a form of 3D printing, in the late 1980s.},
	language = {eng},
	urldate = {2022-01-21},
	month = sep,
	year = {2019},
	file = {Snapshot:/home/tei/Zotero/storage/AJ2XEQUU/fdd000504.html:text/html},
}

@misc{aldandarawy_unity_2019,
	title = {Unity {Cross} {Section} {Shader} {Using} {Shader} {Graph}},
	url = {https://codeburst.io/unity-cross-section-shader-using-shader-graph-31c3fed0fa4f},
	abstract = {F ew years back, I wrote a simple cross section shader in unity using Surface shader, unfortunately  that shader didn’t support different…},
	language = {en},
	urldate = {2022-01-27},
	journal = {Medium},
	author = {Aldandarawy, Abdullah},
	month = dec,
	year = {2019},
	file = {Snapshot:/home/tei/Zotero/storage/KWYJCL3S/unity-cross-section-shader-using-shader-graph-31c3fed0fa4f.html:text/html},
}

@misc{noauthor_mirror_nodate,
	title = {Mirror {Networking} – {Open} {Source} {Networking} for {Unity}},
	url = {https://mirror-networking.com/},
	language = {en-US},
	urldate = {2022-01-31},
	file = {Snapshot:/home/tei/Zotero/storage/25VSQ58L/mirror-networking.com.html:text/html},
}

@misc{technologies_unity_nodate,
	title = {Unity - {Manual}: {Unity} {XR} {Input}},
	shorttitle = {Unity - {Manual}},
	url = {https://docs.unity3d.com/Manual/xr_input.html},
	language = {en},
	urldate = {2022-02-02},
	author = {Technologies, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/X33YKRX5/xr_input.html:text/html},
}

@misc{technologies_unity_nodate-1,
	title = {Unity - {Manual}: {Using} {Depth} {Textures}},
	shorttitle = {Unity - {Manual}},
	url = {https://docs.unity3d.com/2019.3/Documentation/Manual/SL-DepthTextures.html},
	language = {en},
	urldate = {2022-02-04},
	author = {Technologies, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/P77S23Q7/SL-DepthTextures.html:text/html},
}

@misc{technologies_unity_nodate-2,
	title = {Unity {Games} {Solutions} - {Create} {2D} {And} {3D} {Games} {\textbar} {Unity}},
	url = {https://unity.com/solutions/game},
	abstract = {Unity game development software enable developers to create high-quality 3D and 2D games and easily deploy across desktop, VR/AR, console, web, and mobile platforms.},
	language = {en},
	urldate = {2022-02-06},
	author = {Technologies, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/37D4AN8Y/game.html:text/html},
}

@misc{doucet_game_2021,
	title = {Game engines on {Steam}: {The} definitive breakdown},
	shorttitle = {Game engines on {Steam}},
	url = {https://www.gamedeveloper.com/business/game-engines-on-steam-the-definitive-breakdown},
	abstract = {Which game engines are most popular on Steam? Lars Doucet got his hands on data to find out how the game engine race is panning out.},
	language = {en},
	urldate = {2022-02-06},
	journal = {Game Developer},
	author = {Doucet, Lars and September 02, Anthony Pecorella and {2021}},
	month = sep,
	year = {2021},
	note = {Section: business},
	file = {Snapshot:/home/tei/Zotero/storage/G5FIIF7J/game-engines-on-steam-the-definitive-breakdown.html:text/html},
}

@misc{technologies_unity_nodate-3,
	title = {Unity - {Manual}: {XR}},
	shorttitle = {Unity - {Manual}},
	url = {https://docs.unity3d.com/Manual/XR.html},
	language = {en},
	urldate = {2022-02-06},
	author = {Technologies, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/GWFTEMZG/XR.html:text/html},
}

@misc{noauthor_openxr_2016,
	title = {{OpenXR} - {High}-performance access to {AR} and {VR} —collectively known as {XR}— platforms and devices},
	url = {https://www.khronos.org/openxr/},
	abstract = {--},
	language = {en},
	urldate = {2022-02-06},
	journal = {The Khronos Group},
	month = dec,
	year = {2016},
	note = {Section: API},
	file = {Snapshot:/home/tei/Zotero/storage/YLMAMQUZ/openxr.html:text/html},
}

@inproceedings{ratcliffe_extended_2021,
	address = {Yokohama Japan},
	title = {Extended {Reality} ({XR}) {Remote} {Research}: a {Survey} of {Drawbacks} and {Opportunities}},
	isbn = {978-1-4503-8096-6},
	shorttitle = {Extended {Reality} ({XR}) {Remote} {Research}},
	url = {https://dl.acm.org/doi/10.1145/3411764.3445170},
	doi = {10.1145/3411764.3445170},
	abstract = {Extended Reality (XR) technology - such as virtual and augmented reality - is now widely used in Human Computer Interaction (HCI), social science and psychology experimentation. However, these experiments are predominantly deployed in-lab with a co-present researcher. Remote experiments, without co-present researchers, have not fourished, despite the success of remote approaches for non-XR investigations. This paper summarises fndings from a 30-item survey of 46 XR researchers to understand perceived limitations and benefts of remote XR experimentation. Our thematic analysis identifes concerns common with non-XR remote research, such as participant recruitment, as well as XR-specifc issues, including safety and hardware variability. We identify potential positive afordances of XR technology, including leveraging data collection functionalities builtin to HMDs (e.g. hand, gaze tracking) and the portability and reproducibility of an experimental setting. We suggest that XR technology could be conceptualised as an interactive technology and a capable data-collection device suited for remote experimentation.},
	language = {en},
	urldate = {2022-02-07},
	booktitle = {Proceedings of the 2021 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ratcliffe, Jack and Soave, Francesco and Bryan-Kinns, Nick and Tokarchuk, Laurissa and Farkhatdinov, Ildar},
	month = may,
	year = {2021},
	pages = {1--13},
	file = {Ratcliffe et al. - 2021 - Extended Reality (XR) Remote Research a Survey of.pdf:/home/tei/Zotero/storage/4VNBTQE6/Ratcliffe et al. - 2021 - Extended Reality (XR) Remote Research a Survey of.pdf:application/pdf},
}

@misc{experience_modes_nodate,
	title = {Modes in {User} {Interfaces}: {When} {They} {Help} and {When} {They} {Hurt} {Users}},
	shorttitle = {Modes in {User} {Interfaces}},
	url = {https://www.nngroup.com/articles/modes/},
	abstract = {In a modal interface, the same user action can have different results depending on the state of the system. Poorly signaled modes can easily trigger user errors with disastrous consequences.},
	language = {en},
	urldate = {2022-02-07},
	journal = {Nielsen Norman Group},
	author = {Experience, World Leaders in Research-Based User},
	file = {Snapshot:/home/tei/Zotero/storage/K5SAJLPB/modes.html:text/html},
}

@misc{noauthor_xr_nodate,
	title = {{XR} {Interaction} {Toolkit} {\textbar} {XR} {Interaction} {Toolkit} {\textbar} 2.0.0-pre.7},
	url = {https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit@2.0/manual/index.html},
	urldate = {2022-02-07},
	file = {XR Interaction Toolkit | XR Interaction Toolkit | 2.0.0-pre.7:/home/tei/Zotero/storage/EH3GFTHJ/index.html:text/html},
}

@misc{resourcesload_unity_nodate,
	title = {Unity - {Scripting} {API}: {Resources}.{Load}},
	shorttitle = {Unity - {Scripting} {API}},
	url = {https://docs.unity3d.com/ScriptReference/Resources.Load.html},
	language = {en},
	urldate = {2022-02-11},
	author = {resources.load, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/5RAK74J3/Resources.Load.html:text/html},
}

@misc{scriptedimporters_unity_nodate,
	title = {Unity - {Manual}: {Scripted} {Importers}},
	shorttitle = {Unity - {Manual}},
	url = {https://docs.unity3d.com/Manual/ScriptedImporters.html},
	language = {en},
	urldate = {2022-02-11},
	author = {scriptedimporters, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/5UGZTIMW/ScriptedImporters.html:text/html},
}

@misc{textassets_unity_nodate,
	title = {Unity - {Manual}: {Text} assets},
	shorttitle = {Unity - {Manual}},
	url = {https://docs.unity3d.com/Manual/class-TextAsset.html},
	language = {en},
	urldate = {2022-02-11},
	author = {textassets, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/5QH49R7B/class-TextAsset.html:text/html},
}

@misc{noauthor_fellow_2022,
	title = {Fellow {Oak} {DICOM}},
	url = {https://github.com/fo-dicom/fo-dicom},
	abstract = {Fellow Oak DICOM for .NET, .NET Core, Universal Windows, Android, iOS, Mono and Unity},
	urldate = {2022-02-11},
	publisher = {fo-dicom},
	month = feb,
	year = {2022},
	note = {original-date: 2015-05-09T13:35:00Z},
	keywords = {c-sharp, dicom, dot-net, fo-dicom, jpeg, medical, medical-imaging, netcore, netstandard, nuget},
}

@misc{arayan_davidarayanezy-slice_2022,
	title = {{DavidArayan}/ezy-slice},
	copyright = {MIT},
	url = {https://github.com/DavidArayan/ezy-slice},
	abstract = {An open source mesh slicer framework for Unity3D Game Engine. Written in C\#.},
	urldate = {2022-02-14},
	author = {Arayan, David},
	month = feb,
	year = {2022},
	note = {original-date: 2015-11-17T08:38:41Z},
}

@misc{noauthor_performance_nodate,
	title = {Performance and {Optimization} {\textbar} {Oculus} {Developers}},
	url = {https://developer.oculus.com/documentation/unity/unity-perf/},
	urldate = {2022-02-14},
	file = {Performance and Optimization | Oculus Developers:/home/tei/Zotero/storage/396PSGVD/unity-perf.html:text/html},
}

@misc{noauthor_microdicom_nodate,
	title = {{MicroDicom} - {Free} {DICOM} viewer and software},
	url = {https://www.microdicom.com/},
	urldate = {2022-03-05},
	file = {MicroDicom - Free DICOM viewer and software:/home/tei/Zotero/storage/CQQYBCSR/www.microdicom.com.html:text/html},
}

@misc{noauthor_dicom_nodate-1,
	title = {{DICOM} {VR} – {Visualizing} and {Manipulating} {Medical} {Imaging} in a {New} {Dimension}},
	url = {http://www.dicomvr.com/},
	language = {en-US},
	urldate = {2022-03-16},
	file = {Snapshot:/home/tei/Zotero/storage/VI2QVPID/www.dicomvr.com.html:text/html},
}

@misc{noauthor_body_nodate,
	title = {The {Body} {VR}: {Anatomy} {Viewer} on {Steam}},
	shorttitle = {The {Body} {VR}},
	url = {https://store.steampowered.com/app/579620/The_Body_VR_Anatomy_Viewer/},
	abstract = {The Body VR: Anatomy Viewer will display 3D volumes generated from traditional CT/MRI scans that will allow radiologists, medical students, and patients to view anatomical scans in entirely new ways. To apply to the private beta contact us at http://TheBodyVR.com/contact/},
	language = {en},
	urldate = {2022-03-16},
}

@misc{noauthor_immersiveview_nodate,
	title = {{ImmersiveView}™ {VR}},
	url = {https://www.immersivetouch.com/immersiveview-vr},
	abstract = {Utilizing CT, CBCT, 3D angiography or MRI data, ImmersiveView converts DICOM scan data into a “digital twin” of the patient and provides a completely unique and unobstructed view of the case in virtual reality.},
	language = {en-US},
	urldate = {2022-03-16},
	journal = {ImmersiveTouch®},
}

@misc{noauthor_medicalimagingvr_nodate,
	title = {{MedicalImagingVR} on {Steam}},
	url = {https://store.steampowered.com/app/1471980/MedicalImagingVR/},
	abstract = {This educational game allows to learn about medical imaging, how to localize different regions in the human head.},
	language = {en},
	urldate = {2022-03-16},
	file = {Snapshot:/home/tei/Zotero/storage/35Q26WVH/MedicalImagingVR.html:text/html},
}

@misc{noauthor_virtual_nodate,
	title = {Virtual {Reality} for {Surgery} {\textbar} {Precison} {XR}},
	url = {https://surgicaltheater.com/},
	abstract = {View surgeries and medical imaging like never before with Surgical Theater's virtual reality technology, Precision XR.},
	language = {en-US},
	urldate = {2022-03-16},
	journal = {Surgical Theater},
	file = {Snapshot:/home/tei/Zotero/storage/YBAQCMK4/www.surgicaltheater.com.html:text/html},
}

@article{anthony_patient-specific_2021,
	title = {Patient-specific virtual reality technology for complex neurosurgical cases: illustrative cases},
	volume = {1},
	shorttitle = {Patient-specific virtual reality technology for complex neurosurgical cases},
	url = {https://thejns.org/caselessons/view/journals/j-neurosurg-case-lessons/1/23/article-CASE21114.xml},
	doi = {10.3171/CASE21114},
	abstract = {BACKGROUND Virtual reality (VR) offers an interactive environment for visualizing the intimate three-dimensional (3D) relationship between a patient’s pathology and surrounding anatomy. The authors present a model for using personalized VR technology, applied across the neurosurgical treatment continuum from the initial consultation to preoperative surgical planning, then to intraoperative navigation, and finally to postoperative visits, for various tumor and vascular pathologies. OBSERVATIONS Five adult patients undergoing procedures for spinal cord cavernoma, clinoidal meningioma, anaplastic oligodendroglioma, giant aneurysm, and arteriovenous malformation were included. For each case, 360-degree VR (360°VR) environments developed using Surgical Theater were used for patient consultation, preoperative planning, and/or intraoperative 3D navigation. The custom 360°VR model was rendered from the patient’s preoperative imaging. For two cases, the plan changed after reviewing the patient’s 360°VR model from one based on conventional Digital Imaging and Communications in Medicine imaging. LESSONS Live 360° visualization with Surgical Theater in conjunction with surgical navigation helped validate the decisions made intraoperatively. The 360°VR models provided visualization to better understand the lesion’s 3D anatomy, as well as to plan and execute the safest patient-specific approach, rather than a less detailed, more standardized one. In all cases, preoperative planning using the patient’s 360°VR model had a significant impact on the surgical approach.},
	language = {EN},
	number = {23},
	urldate = {2022-03-16},
	journal = {Journal of Neurosurgery: Case Lessons},
	author = {Anthony, Diana and Louis, Robert G. and Shekhtman, Yevgenia and Steineke, Thomas and Frempong-Boadu, Anthony and Steinberg, Gary K.},
	month = jun,
	year = {2021},
	note = {Publisher: American Association of Neurological Surgeons
Section: Journal of Neurosurgery: Case Lessons},
	file = {Full Text PDF:/home/tei/Zotero/storage/I3JXLDV4/Anthony et al. - 2021 - Patient-specific virtual reality technology for co.pdf:application/pdf;Snapshot:/home/tei/Zotero/storage/R5BRQTXA/article-CASE21114.html:text/html},
}

@article{wright_back_2020,
	title = {Back to the future: surgical rehearsal platform technology as a means to improve surgeon-patient alliance, patient satisfaction, and resident experience},
	volume = {135},
	issn = {1933-0693, 0022-3085},
	shorttitle = {Back to the future},
	url = {https://thejns.org/view/journals/j-neurosurg/135/2/article-p384.xml},
	doi = {10.3171/2020.6.JNS201865},
	abstract = {OBJECTIVE Informed consent, when performed appropriately, serves many roles beyond simply obtaining the prerequisite medicolegal paperwork to perform a surgery. Prior studies have suggested that patient understanding is poor when verbal communication is the sole means of education. Virtual reality platforms have proven effective in enhancing medical education. No studies exist that have demonstrated the utility of virtual reality–facilitated informed consent (VR-IC) in improving the physician-patient alliance. The aim of this study was to determine the utility of VR-IC among patients providing consent for surgery and the impact of this educational and information technology–based strategy on enhancing the physician-patient alliance, patient satisfaction, and resident-physician perception of the consent process. METHODS Prospective, single-site, pre- and postconsent surveys were administered to assess patient and resident perception of informed consent performed with the aid of VR-IC at a large tertiary academic medical center in the US. Participants were adult patients (n = 50) undergoing elective surgery for tumor resection and neurosurgical residents (n = 19) who obtained patient informed consent for these surgical procedures. Outcome measures included scores on the Patient-Doctor Relationship Questionnaire (PDRQ-9), the modified Satisfaction with Simulation Experience Scale, and the Maslach Burnout Inventory. Patient pre- and postconsent data were recorded in real time using a secure online research data platform (REDCap). RESULTS A total of 48 patients and 2 family members provided consent using VR-IC and completed the surveys pre- and postconsent; 47.9\% of patients were women. The mean patient age was 57.5 years. There was a statistically significant improvement from pre- to post–VR-IC consent in patient satisfaction scores. Measures of patient-physician alliance, trust, and understanding of their illness all increased. Among the 19 trainees, perceived comfort and preparedness with the informed consent process significantly improved. CONCLUSIONS VR-IC led to improved patient satisfaction, patient-physician alliance, and patient understanding of their illness as measured by the PDRQ-9. Using VR-IC contributed to residents’ increased comfort in the consent-gathering process and handling patient questions. In an era in which satisfaction scores are directly linked with hospital and service-line outcomes and reimbursement, positive results from VR-IC may augment physician and hospital satisfaction scores in addition to increasing measures of trust between physicians and patients.},
	language = {EN},
	number = {2},
	urldate = {2022-03-16},
	journal = {Journal of Neurosurgery},
	author = {Wright, James M. and Raghavan, Alankrita and Wright, Christina H. and Shammassian, Berje and Duan, Yifei and Sajatovic, Martha and Selman, Warren R.},
	month = oct,
	year = {2020},
	note = {Publisher: American Association of Neurological Surgeons
Section: Journal of Neurosurgery},
	pages = {384--391},
	file = {Full Text PDF:/home/tei/Zotero/storage/T7SCVS44/Wright et al. - 2020 - Back to the future surgical rehearsal platform te.pdf:application/pdf;Snapshot:/home/tei/Zotero/storage/EEYUV3WR/article-p384.html:text/html},
}

@misc{noauthor_commandep_nodate,
	title = {{CommandEP} – {SentiAR}},
	url = {https://sentiar.com/commandep/},
	language = {en-US},
	urldate = {2022-03-16},
	file = {Snapshot:/home/tei/Zotero/storage/63E562ZH/commandep.html:text/html},
}

@article{andrews_extended_2019,
	title = {Extended {Reality} in {Medical} {Practice}},
	volume = {21},
	issn = {1092-8464},
	doi = {10.1007/s11936-019-0722-7},
	abstract = {PURPOSE OF REVIEW: Advances in display technology and computing have led to new devices capable of overlaying digital information onto the physical world or incorporating aspects of the physical world into virtual scenes. These combinations of digital and physical environments are referred to as extended realities. Extended reality (XR) devices offer many advantages for medical applications including realistic 3D visualization and touch-free interfaces that can be used in sterile environments. This review introduces extended reality and describes how it can be applied to medical practice.
RECENT FINDINGS: The 3D displays of extended reality devices are valuable in situations where spatial information such as patient anatomy and medical instrument position is important. Applications that take advantage of these 3D capabilities include teaching and pre-operative planning. The utility of extended reality during interventional procedures has been demonstrated with through 3D visualizations of patient anatomy, scar visualization, and real-time catheter tracking with touch-free software control. Extended reality devices have been applied to education, pre-procedural planning, and cardiac interventions. These devices excel in settings where traditional devices are difficult to use, such as in the cardiac catheterization lab. New applications of extended reality in cardiology will continue to emerge as the technology improves.},
	language = {eng},
	number = {4},
	journal = {Current Treatment Options in Cardiovascular Medicine},
	author = {Andrews, Christopher and Southworth, Michael K. and Silva, Jennifer N. A. and Silva, Jonathan R.},
	month = mar,
	year = {2019},
	pmid = {30929093},
	pmcid = {PMC6919549},
	keywords = {Display technology, Extended reality devices, Informatics},
	pages = {18},
	file = {Accepted Version:/home/tei/Zotero/storage/ZVIBIHPE/Andrews et al. - 2019 - Extended Reality in Medical Practice.pdf:application/pdf},
}

@article{mertz_virtual_2019,
	title = {Virtual {Reality} {Pioneer} {Tom} {Furness} on the {Past}, {Present}, and {Future} of {VR} in {Health} {Care}},
	volume = {10},
	issn = {2154-2287, 2154-2317},
	url = {https://ieeexplore.ieee.org/document/8720292/},
	doi = {10.1109/MPULS.2019.2911808},
	language = {en},
	number = {3},
	urldate = {2022-04-04},
	journal = {IEEE Pulse},
	author = {Mertz, Leslie},
	month = may,
	year = {2019},
	pages = {9--11},
	file = {Mertz - 2019 - Virtual Reality Pioneer Tom Furness on the Past, P.pdf:/home/tei/Zotero/storage/LJS4683Z/Mertz - 2019 - Virtual Reality Pioneer Tom Furness on the Past, P.pdf:application/pdf},
}

@article{shahrubudin_overview_2019,
	series = {The 2nd {International} {Conference} on {Sustainable} {Materials} {Processing} and {Manufacturing}, {SMPM} 2019, 8-10 {March} 2019, {Sun} {City}, {South} {Africa}},
	title = {An {Overview} on {3D} {Printing} {Technology}: {Technological}, {Materials}, and {Applications}},
	volume = {35},
	issn = {2351-9789},
	shorttitle = {An {Overview} on {3D} {Printing} {Technology}},
	url = {https://www.sciencedirect.com/science/article/pii/S2351978919308169},
	doi = {10.1016/j.promfg.2019.06.089},
	abstract = {Digital fabrication technology, also referred to as 3D printing or additive manufacturing, creates physical objects from a geometrical representation by successive addition of materials. 3D printing technology is a fast-emerging technology. Nowadays, 3D Printing is widely used in the world. 3D printing technology increasingly used for the mass customization, production of any types of open source designs in the field of agriculture, in healthcare, automotive industry, locomotive industry and aviation industries. 3D printing technology can print an object layer by layer deposition of material directly from a computer aided design (CAD) model. This paper presents the overview of the types of 3D printing technologies, the application of 3D printing technology and lastly, the materials used for 3D printing technology in manufacturing industry.},
	language = {en},
	urldate = {2022-04-05},
	journal = {Procedia Manufacturing},
	author = {Shahrubudin, N. and Lee, T. C. and Ramlan, R.},
	month = jan,
	year = {2019},
	keywords = {3D Printing, Additive manufacuting, manufacturing industy},
	pages = {1286--1296},
	file = {ScienceDirect Full Text PDF:/home/tei/Zotero/storage/HVCYT2SL/Shahrubudin et al. - 2019 - An Overview on 3D Printing Technology Technologic.pdf:application/pdf;ScienceDirect Snapshot:/home/tei/Zotero/storage/EFNDYHRX/S2351978919308169.html:text/html},
}

@article{javaid_virtual_2020,
	title = {Virtual reality applications toward medical field},
	volume = {8},
	issn = {2213-3984},
	url = {https://www.sciencedirect.com/science/article/pii/S2213398419304294},
	doi = {10.1016/j.cegh.2019.12.010},
	abstract = {Background/objectives
Virtual Reality (VR) is a developing technology, which seems to have extensive applications in different areas such as entertainment, sports, gaming and simulation. In the current scenario, due to Computer-generated imagery and content aim at simulating a real presence through senses capability, it has functional applications in the medical field. So, there are requirements to study its applicability in the medical field.
Methods
Relevant papers on VR in the context of the medical field are identified and studied. This paper is a literature review based analysis, where we are trying to find how this technology is going to solve a medical-related problem in saving the life of the patient and what are the significant applications.
Results
VR provides a simulated environment to interact with the 3D world. Medical professionals are developing and implementing this technology for training, diagnosis and virtual treatment during a critical situation. The study sees that there is good potential for VR in the medical field. We also studied the processes involved in implementing this technology in the medical field. Finally, this paper identifies fourteen major applications of VR in the medical field with description. This technology is helping to create quality healthcare services during complicated cases.
Conclusions
VR is used effectively for better surgical technique. It creates detailed virtual models of a patient's anatomy. It helps physicians to effectively move around and view virtual 3D images from different angles. This technology is currently applied in cardiology and Neurology for monitoring and improves patient outcomes. It plays a significant role to help physician related to trauma and other fractures. VR is an emerging technology which can also be used in hospitals and clinics for rehabilitation \& training approaches. The applications of this technology are in virtual guides and to fulfil different other virtual goals in the medical field. It seems like an efficient technology to teach body fitness and help create a positive impact on doctors and the patient. This technology leads to creative and exciting discoveries in the medical field.},
	language = {en},
	number = {2},
	urldate = {2022-04-07},
	journal = {Clinical Epidemiology and Global Health},
	author = {Javaid, Mohd and Haleem, Abid},
	month = jun,
	year = {2020},
	keywords = {3D virtual data, Diagnosis, Medical, Training, Treatment, Virtual reality (VR)},
	pages = {600--605},
	file = {Full Text:/home/tei/Zotero/storage/GRRZA4EZ/Javaid and Haleem - 2020 - Virtual reality applications toward medical field.pdf:application/pdf;ScienceDirect Snapshot:/home/tei/Zotero/storage/KDB7AKRB/S2213398419304294.html:text/html},
}

@article{andrews_extended_2019-1,
	title = {Extended {Reality} in {Medical} {Practice}},
	volume = {21},
	issn = {1534-3189},
	url = {https://doi.org/10.1007/s11936-019-0722-7},
	doi = {10.1007/s11936-019-0722-7},
	abstract = {Advances in display technology and computing have led to new devices capable of overlaying digital information onto the physical world or incorporating aspects of the physical world into virtual scenes. These combinations of digital and physical environments are referred to as extended realities. Extended reality (XR) devices offer many advantages for medical applications including realistic 3D visualization and touch-free interfaces that can be used in sterile environments. This review introduces extended reality and describes how it can be applied to medical practice.},
	language = {en},
	number = {4},
	urldate = {2022-04-09},
	journal = {Current Treatment Options in Cardiovascular Medicine},
	author = {Andrews, Christopher and Southworth, Michael K. and Silva, Jennifer N. A. and Silva, Jonathan R.},
	month = mar,
	year = {2019},
	pages = {18},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/WN52QN2F/Andrews et al. - 2019 - Extended Reality in Medical Practice.pdf:application/pdf},
}

@misc{noauthor_set_nodate,
	title = {Set {Up} {Hand} {Tracking} {\textbar} {Oculus} {Developers}},
	url = {https://developer.oculus.com/documentation/unity/unity-handtracking/},
	urldate = {2022-04-10},
	file = {Set Up Hand Tracking | Oculus Developers:/home/tei/Zotero/storage/AEQM89ZQ/unity-handtracking.html:text/html},
}

@article{kern_audio_2020,
	title = {Audio in {VR}: {Effects} of a {Soundscape} and {Movement}-{Triggered} {Step} {Sounds} on {Presence}},
	volume = {7},
	issn = {2296-9144},
	shorttitle = {Audio in {VR}},
	url = {https://www.frontiersin.org/article/10.3389/frobt.2020.00020},
	abstract = {For effective virtual realities, “presence,” the feeling of “being there” in a virtual environment (VR), is deemed an essential prerequisite. Several studies have assessed the effect of the (non-)availability of auditory stimulation on presence, but due to differences in study design (e.g., virtual realities used, types of sounds included, rendering technologies employed), generalizing the results and estimating the effect of the auditory component is difficult. In two experiments, the influence of an ambient nature soundscape and movement-triggered step sounds were investigated regarding their effects on presence. In each experiment, approximately forty participants walked on a treadmill, thereby strolling through a virtual park environment reproduced via a stereoscopic head-mounted display (HMD), while the acoustical environment was delivered via noise-canceling headphones. In Experiment 1, conditions with the ambient soundscape and the step sounds either present or absent were combined in a 2 × 2 within-subjects design, supplemented with an additional “no-headphones” control condition. For the synchronous playback of step sounds, the probability of a step being taken was estimated by an algorithm using the HMD's sensor data. The results of Experiment 1 show that questionnaire-based measures of presence and realism were influenced by the soundscape but not by the reproduction of steps, which might be confounded with the fact that the perceived synchronicity of the sensor-triggered step sounds was rated rather low. Therefore, in Experiment 2, the step-reproduction algorithm was improved and judged to be more synchronous by participants. Consequently, large and statistically significant effects of both kinds of audio manipulations on perceived presence and realism were observed, with the effect of the soundscape being larger than that of including footstep sounds, possibly due to the remaining imperfections in the reproduction of steps. Including an appropriate soundscape or self-triggered footsteps had differential effects on subscales of presence, in that both affected overall presence and realism, while involvement was improved and distraction reduced by the ambient soundscape only.},
	urldate = {2022-04-10},
	journal = {Frontiers in Robotics and AI},
	author = {Kern, Angelika C. and Ellermeier, Wolfgang},
	year = {2020},
	file = {Full Text PDF:/home/tei/Zotero/storage/NVI2LIH4/Kern and Ellermeier - 2020 - Audio in VR Effects of a Soundscape and Movement-.pdf:application/pdf},
}

@article{cignoni_meshlab_2008,
	title = {{MeshLab}: an {Open}-{Source} {Mesh} {Processing} {Tool}},
	shorttitle = {{MeshLab}},
	url = {http://diglib.eg.org/handle/10.2312/LocalChapterEvents.ItalChap.ItalianChapConf2008.129-136},
	doi = {10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136},
	abstract = {The paper presents MeshLab, an open source, extensible, mesh processing system that has been developed at the Visual Computing Lab of the ISTI-CNR with the helps of tens of students. We will describe the MeshLab architecture, its main features and design objectives discussing what strategies have been used to support its development. Various examples of the practical uses of MeshLab in research and professional frameworks are reported to show the various capabilities of the presented system.},
	language = {en},
	urldate = {2022-04-10},
	journal = {Eurographics Italian Chapter Conference},
	author = {Cignoni, Paolo and Callieri, Marco and Corsini, Massimiliano and Dellepiane, Matteo and Ganovelli, Fabio and Ranzuglia, Guido},
	year = {2008},
	note = {Artwork Size: 8 pages
ISBN: 9783905673685
Publisher: The Eurographics Association},
	keywords = {Categories and Subject Descriptors (according to ACM CCS): I.3.3 [Computer Graphics]: Line and Curve Generation},
	pages = {8 pages},
}

@book{ebnezar_textbook_2016,
	title = {Textbook of {Orthopedics}},
	isbn = {978-93-86056-68-9},
	abstract = {This book is a comprehensive guide to orthopaedics for postgraduate medical students. The fifth edition has been fully revised to present the latest developments and understanding in the field. The book covers numerous injuries and disorders, with each topic beginning with an overview of relevant anatomy, followed by principles and methods of diagnosis and clinical and surgical management. Each chapter includes a brief summary outlining key points, as well as example X-Rays for the topic in discussion. The fifth edition features new sections on trauma, geriatric orthopaedics, arthroscopy, and surgical techniques, as well as additional images including new X-Rays and MRI scans, and line diagrams.   Key Points  Comprehensive guide to orthopaedics for postgraduate medical students Fully revised, fifth edition with new topics More than 1300 clinical images and diagrams, many new to this edition Previous edition (9788184487442) published in 2010},
	language = {en},
	publisher = {JP Medical Ltd},
	author = {Ebnezar, John and John, Rakesh},
	month = dec,
	year = {2016},
	note = {Google-Books-ID: 0efhjwEACAAJ},
	keywords = {Medical / Orthopedics, Medical / Surgery / General},
}

@misc{gameengine_what_nodate,
	title = {What is a {Game} {Engine}? {\textbar} {University} of {Silicon} {Valley}},
	shorttitle = {What is a {Game} {Engine}?},
	url = {https://usv.edu/blog/what-is-a-game-engine/},
	abstract = {Video games are an art form that combines and incorporates multiple artistic mediums to create a cohesive gaming world. Creating believable virtual worlds is a demanding task that requires special software to keep everything from freezing during runtime. To help keep all the spinning plates from crashing to the floor, developers use a game engine.},
	language = {en},
	urldate = {2022-04-28},
	author = {gameengine},
	file = {Snapshot:/home/tei/Zotero/storage/DGUTBPP8/what-is-a-game-engine.html:text/html},
}

@misc{entitycomponent_entities_nodate,
	title = {Entities overview {\textbar} {Entities} {\textbar} 0.50.1-preview.2},
	url = {https://docs.unity3d.com/Packages/com.unity.entities@0.50/manual/index.html},
	urldate = {2022-04-28},
	author = {entitycomponent},
	file = {Entities overview | Entities | 0.50.1-preview.2:/home/tei/Zotero/storage/Y4R8NUVQ/index.html:text/html},
}

@misc{obj_wavefront_nodate,
	title = {Wavefront {OBJ}: {Summary} from the {Encyclopedia} of {Graphics} {File} {Formats}},
	url = {https://www.fileformat.info/format/wavefrontobj/egff.htm},
	urldate = {2022-04-29},
	author = {obj},
	file = {Wavefront OBJ\: Summary from the Encyclopedia of Graphics File Formats:/home/tei/Zotero/storage/82HTXEYC/egff.html:text/html},
}

@misc{intel_virtual_nodate,
	title = {Virtual {Reality} vs. {Augmented} {Reality} vs. {Mixed} {Reality}},
	url = {https://www.intel.com/content/www/us/en/tech-tips-and-tricks/virtual-reality-vs-augmented-reality.html},
	abstract = {Learn more about Virtual Reality vs. Augmented Reality vs. Mixed Reality and the computing requirements of these experimental technologies.},
	language = {en},
	urldate = {2022-05-01},
	journal = {Intel},
	author = {Intel},
	file = {Snapshot:/home/tei/Zotero/storage/H2EM826M/virtual-reality-vs-augmented-reality.html:text/html},
}

@misc{hololens_microsoft_nodate,
	title = {Microsoft {HoloLens} {\textbar} {Mixed} {Reality} {Technology} for {Business}},
	url = {https://www.microsoft.com/en-us/hololens},
	abstract = {Introducing HoloLens 2, an untethered mixed reality headset that's designed to help you solve real business problems today using intelligent apps and solutions.},
	language = {en-us},
	urldate = {2022-05-01},
	author = {hololens},
	file = {Snapshot:/home/tei/Zotero/storage/5TXED5GH/hololens.html:text/html},
}

@misc{vrdesign_best_nodate,
	title = {The best practices and design principles of {VR} development},
	url = {https://www.gamesindustry.biz/articles/2020-04-01-the-best-practices-and-design-principles-of-vr-development},
	abstract = {VR developers tell the GamesIndustry.biz Academy about the golden rules and design challenges of making games for virtual reality},
	language = {en},
	urldate = {2022-05-03},
	journal = {GamesIndustry.biz},
	author = {vrdesign},
	file = {Snapshot:/home/tei/Zotero/storage/6AU8LW77/2020-04-01-the-best-practices-and-design-principles-of-vr-development.html:text/html},
}

@misc{vrdesignadobe_virtual_nodate,
	title = {Virtual {Reality} ({VR}) {Design} \& {User} {Experience} {\textbar} {Adobe} {XD} {Ideas}},
	url = {https://xd.adobe.com/ideas/principles/emerging-technology/virtual-reality-design/},
	abstract = {Virtual reality presents unique challenges for designers. Discover how UX principles are applied to create engaging experiences with VR design.},
	language = {en-US},
	urldate = {2022-05-03},
	journal = {Ideas},
	author = {vrDesignAdobe},
	note = {Section: Emerging Technology},
	file = {Snapshot:/home/tei/Zotero/storage/9SQRHQK5/virtual-reality-design.html:text/html},
}

@article{cynthia_l_foronda_virtual_nodate,
	title = {Virtual {Simulation} in {Nursing} {Education}: {A} {Systematic} {Review} {Spanning} 1996 to 2018},
	author = {Cynthia L. Foronda},
}

@misc{system_usability_scale_sus_system_2013,
	title = {System {Usability} {Scale} ({SUS})},
	url = {https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html},
	abstract = {The System Usability Scale (SUS) is a reliable tool for measuring the usability.   It consists of a 10 item questionnaire with five response options for respondents; from Strongly agree to Strongly disagree.},
	language = {en-us},
	urldate = {2022-05-06},
	author = {System Usability Scale (SUS)},
	month = sep,
	year = {2013},
	note = {Publisher: Department of Health and Human Services},
	file = {Snapshot:/home/tei/Zotero/storage/X3QDPZY8/system-usability-scale.html:text/html},
}

@misc{affairs_system_2013,
	title = {System {Usability} {Scale} ({SUS})},
	url = {https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html},
	abstract = {The System Usability Scale (SUS) is a reliable tool for measuring the usability.   It consists of a 10 item questionnaire with five response options for respondents; from Strongly agree to Strongly disagree.},
	language = {en-us},
	urldate = {2022-05-06},
	author = {Affairs, Assistant Secretary for Public},
	month = sep,
	year = {2013},
	note = {Publisher: Department of Health and Human Services},
	file = {Snapshot:/home/tei/Zotero/storage/73XDNE4Q/system-usability-scale.html:text/html},
}

@misc{verywell_health_fracture_nodate,
	title = {Fracture {Reduction} and {Why} {It} {Matters} to {Your} {Physical} {Therapist}},
	url = {https://www.verywellhealth.com/fracture-reduction-2696125},
	abstract = {Learn how your healthcare provider can fix a broken bone and how physical therapy can help improve function after a fracture.},
	language = {en},
	urldate = {2022-05-07},
	journal = {Verywell Health},
	author = {verywell health},
	note = {Section: Verywell},
	file = {Snapshot:/home/tei/Zotero/storage/UTINA26Y/fracture-reduction-2696125.html:text/html},
}

@misc{tyriel_wood_-_vr_tech_oculus_2019,
	title = {Oculus {Quest} {VS} {PC} - {Graphics} side-by-side {Comparison} - {Apex} {Construct}},
	url = {https://www.youtube.com/watch?v=btb0gJT200U},
	abstract = {HERE is my comparison Between the Oculus Quest and the PC VR versions of Apex Construct. Is it a real downgrade? What are the capabilities of this new Standalone Virtual Reality Headset? 

Let me know what you think about it in the comments below!

A big thank you to Oculus for sending me this headset to review so that all of you can be informed before it hits stores on May 21st!

Also, since we have hit 10k followers before May 21st, you can win your very own Oculus Quest by entering here:

https://gleam.io/TjE9y/tyriel-wood-oc...

I want to thank each and everyone of you for the support that you have given me so I am buying a headset with my own money for one of you lucky VR loving people!

Where to Buy: 
Oculus QUEST 64 GB: https://amzn.to/2ZL7ew4
Oculus QUEST 128GB: https://amzn.to/2GTI7zG

Oculus Rift S: https://amzn.to/2DGbEeh

Join the discussion HERE
DISCORD Channel: https://discord.gg/mgegukz -- Let's Chat!

❤ You can Join and Support the Channel Here for Great Perks too: https://www.youtube.com/channel/UC5rM... :)

► For the Next videos and to get all the information: https://goo.gl/5oZXwo 

► If you think it was great and useful YOU can Help and support the channel Here (It's really hard to buy everything to Review 😢 ): https://www.youtube.com/channel/UC5rM... or  https://paypal.me/pools/c/85FYBKkMRp

►Check everything we feature on the Channel in the Tyriel Wood Amazon Shop: https://www.amazon.com/shop/tyrielwood

► Be sure to follow me on Twitter https://twitter.com/Tyrielwood and Instagram/IGTV https://www.instagram.com/tyrielwoodvr/ 

► AND SUBSCRIBE to the channel to keep up to date with all of the coverage! https://goo.gl/5oZXwo 


TYRIEL WOOD SHOP: https://www.amazon.com/shop/tyrielwood

Oculus Rift: https://amzn.to/2pJd7sw 

Oculus GO: https://amzn.to/2pJi4Sf 

Oculus Sensor: https://amzn.to/2zZ7Hjb 

VRCovers HERE: https://vrcover.com/?itm=274

Ni-Zi BATTERIES: https://amzn.to/2DSxOvy

Samsung Odyssey Plus: https://amzn.to/2GjMrJB

Samsung Hmd Odyssey: https://amzn.to/2R4JUUH

HTC Vive Pro: https://www.amazon.com/HTC-VIVE-Virtu... 

HTC Vive Wireless Adaptor: https://amzn.to/2PKOFTe 

--------

good morning by Amine Maxwell https://soundcloud.com/aminemaxwell
Creative Commons — Attribution 3.0 Unported  — CC BY 3.0 
http://creativecommons.org/licenses/b...
Music promoted by Audio Library https://youtu.be/SQWFdnbzlgI

\#OculusQuest \#VS \#PC},
	urldate = {2022-05-14},
	author = {{Tyriel Wood - VR Tech}},
	month = may,
	year = {2019},
}

@article{bangor_empirical_2008,
	title = {An {Empirical} {Evaluation} of the {System} {Usability} {Scale}},
	volume = {24},
	issn = {1044-7318},
	url = {https://doi.org/10.1080/10447310802205776},
	doi = {10.1080/10447310802205776},
	abstract = {This article presents nearly 10 year's worth of System Usability Scale (SUS) data collected on numerous products in all phases of the development lifecycle. The SUS, developed by Brooke (1996), reflected a strong need in the usability community for a tool that could quickly and easily collect a user's subjective rating of a product's usability. The data in this study indicate that the SUS fulfills that need. Results from the analysis of this large number of SUS scores show that the SUS is a highly robust and versatile tool for usability professionals. The article presents these results and discusses their implications, describes nontraditional uses of the SUS, explains a proposed modification to the SUS to provide an adjective rating that correlates with a given score, and provides details of what constitutes an acceptable SUS score.},
	number = {6},
	urldate = {2022-05-23},
	journal = {International Journal of Human–Computer Interaction},
	author = {Bangor, Aaron and Kortum, Philip T. and Miller, James T.},
	month = jul,
	year = {2008},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447310802205776},
	pages = {574--594},
}

@article{razzouk_what_2012,
	title = {What {Is} {Design} {Thinking} and {Why} {Is} {It} {Important}?},
	volume = {82},
	issn = {0034-6543},
	url = {https://doi.org/10.3102/0034654312457429},
	doi = {10.3102/0034654312457429},
	abstract = {Design thinking is generally defined as an analytic and creative process that engages a person in opportunities to experiment, create and prototype models, gather feedback, and redesign. Several characteristics (e.g., visualization, creativity) that a good design thinker should possess have been identified from the literature. The primary purpose of this article is to summarize and synthesize the research on design thinking to (a) better understand its characteristics and processes, as well as the differences between novice and expert design thinkers, and (b) apply the findings from the literature regarding the application of design thinking to our educational system. The authors’ overarching goal is to identify the features and characteristics of design thinking and discuss its importance in promoting students’ problem-solving skills in the 21st century.},
	language = {en},
	number = {3},
	urldate = {2022-05-26},
	journal = {Review of Educational Research},
	author = {Razzouk, Rim and Shute, Valerie},
	month = sep,
	year = {2012},
	note = {Publisher: American Educational Research Association},
	keywords = {design process, design thinking, expert and novice, expertise},
	pages = {330--348},
	file = {SAGE PDF Full Text:/home/tei/Zotero/storage/HRSZ6WF2/Razzouk and Shute - 2012 - What Is Design Thinking and Why Is It Important.pdf:application/pdf},
}

@article{uppot_implementing_2019,
	title = {Implementing {Virtual} and {Augmented} {Reality} {Tools} for {Radiology}                     {Education} and {Training}, {Communication}, and {Clinical} {Care}},
	volume = {291},
	issn = {0033-8419},
	url = {https://pubs.rsna.org/doi/full/10.1148/radiol.2019182210},
	doi = {10.1148/radiol.2019182210},
	abstract = {Advances in virtual immersive and augmented reality technology, commercially available for the entertainment and gaming industry, hold potential for education and clinical use in medicine and the field of medical imaging. Radiology departments have begun exploring the use of these technologies to help with radiology education and clinical care. The purpose of this review article is to summarize how three institutions have explored using virtual and augmented reality for radiology.

© RSNA, 2019

Online supplemental material is available for this article.},
	number = {3},
	urldate = {2022-05-26},
	journal = {Radiology},
	author = {Uppot, Raul                         N. and Laguna, Benjamin and McCarthy, Colin                             J. and De                             Novi, Gianluca and Phelps, Andrew and Siegel, Eliot and Courtier, Jesse},
	month = jun,
	year = {2019},
	note = {Publisher: Radiological Society of North America},
	pages = {570--580},
	file = {Full Text PDF:/home/tei/Zotero/storage/R84PC76Q/Uppot et al. - 2019 - Implementing Virtual and Augmented Reality Tools f.pdf:application/pdf},
}

@misc{noauthor_how_2020,
	title = {How {Immerse} {VR} is {Helping} {Radiologists} {Learn} {Life}-{Saving} {X}-{Ray} {Tech} {\textbar} {HealthySimulation}.com},
	url = {https://www.healthysimulation.com/27355/immerse-vr-x-ray-simulator/},
	abstract = {Enterprise VR company Immerse recently worked with GE Healthcare to develop a training program for radiographers that simulates the hands-on experience of completing CTCA scans. Justin Parry COO at Immerse recently shared more with us about their VR platform which is already working with some of the world’s largest companies to create, scale and deploy},
	language = {en-US},
	urldate = {2022-05-26},
	month = oct,
	year = {2020},
	file = {Snapshot:/home/tei/Zotero/storage/26XPVKZ6/immerse-vr-x-ray-simulator.html:text/html},
}
