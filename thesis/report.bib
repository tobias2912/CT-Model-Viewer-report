
@misc{materialise_materialise_2020,
	title = {Materialise {Introduces} {VR} {Capabilities} for {Medical} {Planning} in {Mimics} {Viewer} {\textbar} {Materialise}},
	url = {https://www.materialise.com/en/press-releases/vr-capabilities-for-medical-planning-mimics-viewer},
	language = {en},
	urldate = {2021-06-01},
	author = {materialise},
	month = nov,
	year = {2020},
	file = {Snapshot:/home/tei/Zotero/storage/GQT6F984/vr-capabilities-for-medical-planning-mimics-viewer.html:text/html},
}

@article{mishra_virtual_2019,
	title = {Virtual preoperative planning and {3D} printing are valuable for the management of complex orthopaedic trauma},
	volume = {22},
	issn = {1008-1275},
	doi = {10.1016/j.cjtee.2019.07.006},
	abstract = {PURPOSE: The technology of 3D printing (3DP) exists for quite some time, but it is still not utilized to its full potential in the field of orthopaedics and traumatology, such as underestimating its worth in virtual preoperative planning (VPP) and designing various models, templates, and jigs. It can be a significant tool in the reduction of surgical morbidity and better surgical outcome avoiding various associated complications.
METHODS: An observational study was done including 91 cases of complex trauma presented in our institution requiring operative fixation. Virtual preoperative planning and 3DP were used in the management of these fractures. Surgeons managing these cases were given a set of questionnaire and responses were recorded and assessed as a quantitative data.
RESULTS: In all the 91 cases, where VPP and 3DP were used, the surgeons were satisfied with the outcome which they got intraoperatively and postoperatively. Surgical time was reduced, with a better outcome. Three dimensional models of complex fracture were helpful in understanding the anatomy and sketching out the plans for optimum reduction and fixation. The average score of the questionnaire was 4.5, out of a maximum of 6, suggesting a positive role of 3DP in orthopaedics.
CONCLUSION: 3DP is useful in complex trauma management by accurate reduction and placement of implants, reduction of surgical time and with a better outcome. Although there is an initial learning curve to understand and execute the VPP and 3DP, these become easier with practice and experience.},
	language = {eng},
	number = {6},
	journal = {Chinese Journal of Traumatology = Zhonghua Chuang Shang Za Zhi},
	author = {Mishra, Abhishek and Verma, Tarun and Vaish, Abhishek and Vaish, Riya and Vaishya, Raju and Maini, Lalit},
	month = dec,
	year = {2019},
	pmid = {31668700},
	pmcid = {PMC6921216},
	keywords = {Adult, Bone fractures, Fracture dislocation, Fracture Dislocation, Fractures, Bone, Humans, Male, Operative Time, Orthopedic Procedures, Orthopedic Surgeons, Patient Care Planning, Printing, Three-Dimensional, Surveys and Questionnaires, Three-dimensional printing, Tomography, X-Ray Computed, Treatment Outcome, Virtual Reality, Wounds and Injuries, X-ray computed tomography, Young Adult},
	pages = {350--355},
	file = {Full Text:/home/tei/Zotero/storage/TVQ3UZEY/Mishra et al. - 2019 - Virtual preoperative planning and 3D printing are .pdf:application/pdf},
}

@article{vertemati_virtual_2019,
	title = {A {Virtual} {Reality} {Environment} to {Visualize} {Three}-{Dimensional} {Patient}-{Specific} {Models} by a {Mobile} {Head}-{Mounted} {Display}},
	volume = {26},
	issn = {1553-3506},
	url = {https://doi.org/10.1177/1553350618822860},
	doi = {10.1177/1553350618822860},
	abstract = {Introduction. With the availability of low-cost head-mounted displays (HMDs), virtual reality environments (VREs) are increasingly being used in medicine for teaching and clinical purposes. Our aim was to develop an interactive, user-friendly VRE for tridimensional visualization of patient-specific organs, establishing a workflow to transfer 3-dimensional (3D) models from imaging datasets to our immersive VRE. Materials and Methods. This original VRE model was built using open-source software and a mobile HMD, Samsung Gear VR. For its validation, we enrolled 33 volunteers: morphologists (n = 11), trainee surgeons (n = 15), and expert surgeons (n = 7). They tried our VRE and then filled in an original 5-point Likert-type scale 6-item questionnaire, considering the following parameters: ease of use, anatomy comprehension compared with 2D radiological imaging, explanation of anatomical variations, explanation of surgical procedures, preoperative planning, and experience of gastrointestinal/neurological disorders. Results in the 3 groups were statistically compared using analysis of variance. Results. Using cross-sectional medical imaging, the developed VRE allowed to visualize a 3D patient-specific abdominal scene in 1 hour. Overall, the 6 items were evaluated positively by all groups; only anatomy comprehension was statistically significant different among the 3 groups. Conclusions. Our approach, based on open-source software and mobile hardware, proved to be a valid and well-appreciated system to visualize 3D patient-specific models, paving the way for a potential new tool for teaching and preoperative planning.},
	language = {en},
	number = {3},
	urldate = {2021-06-01},
	journal = {Surgical Innovation},
	author = {Vertemati, Maurizio and Cassin, Simone and Rizzetto, Francesco and Vanzulli, Angelo and Elli, Marco and Sampogna, Gianluca and Gallieni, Maurizio},
	month = jun,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {anatomy, head-mounted display, mobile, training, virtual reality},
	pages = {359--370},
	file = {SAGE PDF Full Text:/home/tei/Zotero/storage/8NA4Y7TR/Vertemati et al. - 2019 - A Virtual Reality Environment to Visualize Three-D.pdf:application/pdf},
}

@article{vinje_mini_nodate,
	title = {Mini invasiv behandling av brudd i hælbeinet ved hjelp av {3D} printing},
	shorttitle = {3dp for brudd i hæl},
	author = {Vinje, Tarjei},
	pages = {22},
	file = {Vinje - Mini invasiv behandling av brudd i hælbeinet ved h.pdf:/home/tei/Zotero/storage/NYXGDKQQ/Vinje - Mini invasiv behandling av brudd i hælbeinet ved h.pdf:application/pdf},
}

@article{chheang_collaborative_2021,
	title = {A collaborative virtual reality environment for liver surgery planning},
	volume = {99},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849321001400},
	doi = {10.1016/j.cag.2021.07.009},
	abstract = {Surgical planning software is a key component in the treatment of tumor diseases. However, desktop-based systems provide only limited visualization and interaction opportunities. Moreover, collaborative planning among members of a surgical team is only possible to a limited extent. In this work, a collaborative virtual reality (VR) environment to assist liver surgeons in tumor surgery planning is presented. Our aim is to improve virtual resection planning between surgeons in a remote or co-located environment. The system allows surgeons to define and adjust virtual resections on patient-specific organ 3D surfaces and 2D image slices. Changes on both modalities are synchronized, which will enable surgeons to iterate and refine the resection surfaces quickly. In addition, a real-time risk map visualization is presented that displays safety margins around tumors. An evaluation performed by liver surgeons provides information on potential benefits, such as the possibility to visualize complex cases and assessing the safety-critical areas, applicability, and limitations for further improvement.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Computers \& Graphics},
	author = {Chheang, Vuthea and Saalfeld, Patrick and Joeres, Fabian and Boedecker, Christian and Huber, Tobias and Huettl, Florentine and Lang, Hauke and Preim, Bernhard and Hansen, Christian},
	month = oct,
	year = {2021},
	keywords = {Human-computer interaction, Medical visualization, Surgical planning, Virtual reality},
	pages = {234--246},
	file = {ScienceDirect Full Text PDF:/home/tei/Zotero/storage/ABM86REF/Chheang et al. - 2021 - A collaborative virtual reality environment for li.pdf:application/pdf;ScienceDirect Snapshot:/home/tei/Zotero/storage/HTT3YQXH/S0097849321001400.html:text/html},
}

@misc{materialise_medical_nodate,
	title = {Medical {3D} {Printing} {\textbar} {3D} {Printing} {In} {Medical} {Field} {\textbar} {Materialise} {Medical}},
	url = {https://www.materialise.com/en/medical},
	abstract = {Premium medical 3D Printing and planning solutions. Complete 3D medical software \& services for healthcare professionals, engineers \& researchers. Better fitting implants, planning advanced clinical procedures; medical image-based planning and medical 3D printing technology is solving the most complex challenges.},
	language = {en},
	urldate = {2021-09-01},
	author = {materialise},
	file = {Snapshot:/home/tei/Zotero/storage/WPXIFYC3/medical.html:text/html},
}

@misc{dicomdirectorcom_surgeons_nodate,
	title = {Surgeons {\textbar} {Solutions} {For} {DICOM} {Done} {Better}, {Faster} + {3D} on every device},
	url = {https://www.dicomdirector.com/for-surgeons/},
	abstract = {DICOM Solution For Surgeons Viewable on Augmented, Virtual Reality devices, or on any Device. Better Surgical Planning, patient prep and more},
	language = {en-US},
	urldate = {2021-09-01},
	journal = {DICOM Director},
	author = {dicomdirector.com},
	file = {Snapshot:/home/tei/Zotero/storage/2WJMN8JV/for-surgeons.html:text/html},
}

@misc{medical_holodeck_medicalholodeck_nodate,
	title = {Medicalholodeck. {The} {Virtual} {Reality} {Platform} for {Medical} {Teamwork}.},
	url = {https://www.medicalholodeck.com/en/},
	abstract = {DICOM Viewer, human anatomy lab and 3D anatomy models for teamwork in virtual reality (VR).},
	language = {en},
	urldate = {2021-09-01},
	author = {Medical Holodeck},
	file = {Snapshot:/home/tei/Zotero/storage/I8M2GC3Z/en.html:text/html},
}

@article{chen_efficacy_2019,
	title = {The efficacy of using {3D} printing models in the treatment of fractures: a randomised clinical trial},
	volume = {20},
	issn = {1471-2474},
	shorttitle = {The efficacy of using {3D} printing models in the treatment of fractures},
	url = {https://doi.org/10.1186/s12891-019-2448-9},
	doi = {10.1186/s12891-019-2448-9},
	abstract = {The aim of this study was to evaluate the efficacy of the use of three-dimensional (3D) printing models for preoperative planning in cases of complex fracture.},
	language = {en},
	number = {1},
	urldate = {2021-09-24},
	journal = {BMC Musculoskeletal Disorders},
	author = {Chen, Chunhui and Cai, Leyi and Zheng, Wenhao and Wang, Jianshun and Guo, Xiaoshan and Chen, Hua},
	month = feb,
	year = {2019},
	pages = {65},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/XEW9GCF5/Chen et al. - 2019 - The efficacy of using 3D printing models in the tr.pdf:application/pdf},
}

@misc{noauthor_visualizing_2017,
	title = {Visualizing {MRI} \& {CT} {Scans} in {Mixed} {Reality} / {VR} / {AR}, {Part} 1: {Importing} {Data}},
	shorttitle = {Visualizing {MRI} \& {CT} {Scans} in {Mixed} {Reality} / {VR} / {AR}, {Part} 1},
	url = {https://www.andreasjakl.com/visualising-mri-ct-scans-in-mixed-reality-vr-ar-part-1-importing-data/},
	abstract = {First part in a step-by-step series to visualize MRI / CT / ultrasound data in 3D using HoloLens and Google ARCore.},
	language = {en-US},
	urldate = {2021-09-27},
	journal = {andreasjakl.com},
	month = oct,
	year = {2017},
	file = {Snapshot:/home/tei/Zotero/storage/FZ5MJC6G/visualising-mri-ct-scans-in-mixed-reality-vr-ar-part-1-importing-data.html:text/html},
}

@techreport{ceevra_inc_using_2019,
	type = {Clinical trial registration},
	title = {Using {Virtual} {Reality} ({VR}) {Models} for {Preoperative} {Planning}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03334344},
	abstract = {A prospective, randomized, controlled study designed to assess whether digital virtual reality (VR) models, created from existing CT scans and MRIs, provide surgeons with an improved understanding of their patients' anatomy, resulting in more efficient operations (robotic partial nephrectomy) and improved patient care.},
	number = {NCT03334344},
	urldate = {2021-09-26},
	institution = {clinicaltrials.gov},
	author = {{Ceevra, Inc.}},
	month = jun,
	year = {2019},
	note = {submitted: November 1, 2017},
}

@misc{noauthor_ceevra_nodate,
	title = {Ceevra {\textbar} {Advanced} {3D} {Visualization} for {Surgeons}},
	url = {https://ceevra.com/},
	language = {en-US},
	urldate = {2021-09-27},
	file = {Snapshot:/home/tei/Zotero/storage/9YFQ2EK9/ceevra.com.html:text/html},
}

@techreport{ceevra_inc_using_2019-1,
	type = {Clinical trial registration},
	title = {Using {Virtual} {Reality} ({VR}) {Models} for {Preoperative} {Planning}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03334344},
	abstract = {A prospective, randomized, controlled study designed to assess whether digital virtual reality (VR) models, created from existing CT scans and MRIs, provide surgeons with an improved understanding of their patients' anatomy, resulting in more efficient operations (robotic partial nephrectomy) and improved patient care.},
	number = {NCT03334344},
	urldate = {2021-10-03},
	institution = {clinicaltrials.gov},
	author = {{Ceevra, Inc.}},
	month = jun,
	year = {2019},
	note = {submitted: November 1, 2017},
}

@article{shirk_effect_2019,
	title = {Effect of 3-{Dimensional} {Virtual} {Reality} {Models} for {Surgical} {Planning} of {Robotic}-{Assisted} {Partial} {Nephrectomy} on {Surgical} {Outcomes}: {A} {Randomized} {Clinical} {Trial}},
	volume = {2},
	issn = {2574-3805},
	shorttitle = {Effect of 3-{Dimensional} {Virtual} {Reality} {Models} for {Surgical} {Planning} of {Robotic}-{Assisted} {Partial} {Nephrectomy} on {Surgical} {Outcomes}},
	doi = {10.1001/jamanetworkopen.2019.11598},
	abstract = {Importance: Planning complex operations such as robotic-assisted partial nephrectomy requires surgeons to review 2-dimensional computed tomography or magnetic resonance images to understand 3-dimensional (3-D), patient-specific anatomy.
Objective: To determine surgical outcomes for robotic-assisted partial nephrectomy when surgeons reviewed 3-D virtual reality (VR) models during operative planning.
Design, Setting, and Participants: A single-blind randomized clinical trial was performed. Ninety-two patients undergoing robotic-assisted partial nephrectomy performed by 1 of 11 surgeons at 6 large teaching hospitals were prospectively enrolled and randomized. Enrollment and data collection occurred from October 2017 through December 2018, and data analysis was performed from December 2018 through March 2019.
Interventions: Patients were assigned to either a control group undergoing usual preoperative planning with computed tomography and/or magnetic resonance imaging only or an intervention group where imaging was supplemented with a 3-D VR model. This model was viewed on the surgeon's smartphone in regular 3-D format and in VR using a VR headset.
Main Outcomes and Measures: The primary outcome measure was operative time. It was hypothesized that the operations performed using the 3-D VR models would have shorter operative time than those performed without the models. Secondary outcomes included clamp time, estimated blood loss, and length of hospital stay.
Results: Ninety-two patients (58 men [63\%]) with a mean (SD) age of 60.9 (11.6) years were analyzed. The analysis included 48 patients randomized to the control group and 44 randomized to the intervention group. When controlling for case complexity and other covariates, patients whose surgical planning involved 3-D VR models showed differences in operative time (odds ratio [OR], 1.00; 95\% CI, 0.37-2.70; estimated OR, 2.47), estimated blood loss (OR, 1.98; 95\% CI, 1.04-3.78; estimated OR, 4.56), clamp time (OR, 1.60; 95\% CI, 0.79-3.23; estimated OR, 11.22), and length of hospital stay (OR, 2.86; 95\% CI, 1.59-5.14; estimated OR, 5.43). Estimated ORs were calculated using the parameter estimates from the generalized estimating equation model. Referent group values for each covariate and the corresponding nephrometry score were summed across the covariates and nephrometry score, and the sum was exponentiated to obtain the OR. A mean of the estimated OR weighted by sample size for each nephrometry score strata was then calculated.
Conclusions and Relevance: This large, randomized clinical trial demonstrated that patients whose surgical planning involved 3-D VR models had reduced operative time, estimated blood loss, clamp time, and length of hospital stay.
Trial Registration: ClinicalTrials.gov identifiers (1 registration per site): NCT03334344, NCT03421418, NCT03534206, NCT03542565, NCT03556943, and NCT03666104.},
	language = {eng},
	number = {9},
	journal = {JAMA network open},
	author = {Shirk, Joseph D. and Thiel, David D. and Wallen, Eric M. and Linehan, Jennifer M. and White, Wesley M. and Badani, Ketan K. and Porter, James R.},
	month = sep,
	year = {2019},
	pmid = {31532520},
	pmcid = {PMC6751754},
	keywords = {Humans, Male, Operative Time, Virtual Reality, Blood Loss, Surgical, Computer Simulation, Female, Glomerular Filtration Rate, Imaging, Three-Dimensional, Length of Stay, Middle Aged, Nephrectomy, Robotic Surgical Procedures, Single-Blind Method},
	pages = {e1911598},
	file = {Full Text:/home/tei/Zotero/storage/CUFZZM48/Shirk et al. - 2019 - Effect of 3-Dimensional Virtual Reality Models for.pdf:application/pdf},
}

@article{brouwers_what_2020,
	title = {What is the value of {3D} virtual reality in understanding acetabular fractures?},
	volume = {30},
	issn = {1633-8065},
	doi = {10.1007/s00590-019-02537-w},
	abstract = {BACKGROUND: Acetabular fractures are difficult to classify owing to the complex three-dimensional (3D) anatomy of the pelvis. 3D printing helps to understand and reliably classify acetabular fracture types. 3D-virtual reality (VR) may have comparable benefits. Our hypothesis is that 3D-VR is equivalent to 3D printing in understanding acetabular fracture patterns.
METHODS: A total of 27 observers of various experience levels from several hospitals were requested to classify twenty 3D printed and VR models according to the Judet-Letournel classification. Additionally, surgeons were asked to state their preferred surgical approach and patient positioning. Time to classify each fracture type was recorded. The cases were randomized to rule out a learning curve. Inter-observer agreement was analyzed using Fleiss' kappa statistics (κ).
RESULTS: Inter-observer agreements varied by observer group and type of model used to classify the fracture: medical students: 3D print (κ = 0.61), VR (κ = 0.41); junior surgical residents: 3D print (0.51) VR (0.54); senior surgical residents: 3D print (0.66) VR (0.52); junior surgeons: 3D print (0.56), VR (0.43); senior surgeons: 3D print (κ = 0.59), VR (κ = 0.42). Using 3D printed models, there was more agreement on the surgical approach (junior surgeons κ = 0.23, senior surgeons κ = 0.31) when compared with VR (junior surgeons κ = 0.17, senior surgeons 0.25). No difference was found in time used to classify these fractures between 3D printing and VR for all groups (P = 1.000).
CONCLUSIONS: The Judet-Letournel acetabular classification stays difficult to interpret; only moderate kappa agreements were found. We found 3D-VR inferior to 3D printing in classifying acetabular fractures. Furthermore, the current 3D-VR technology is still not practical for intra-operative use.},
	language = {eng},
	number = {1},
	journal = {European Journal of Orthopaedic Surgery \& Traumatology: Orthopedie Traumatologie},
	author = {Brouwers, Lars and Pull Ter Gunne, Albert F. and de Jongh, Mariska A. and Maal, Thomas J. J. and Vreeken, Rinaldo and van der Heijden, Frank H. W. M. and Leenen, Luke P. H. and Spanjersberg, Willem R. and van Helden, Sven H. and Verbeek, Diederik O. and Bemelman, Mike and Lansink, Koen W. W.},
	month = jan,
	year = {2020},
	pmid = {31531739},
	keywords = {Adult, Fractures, Bone, Humans, Male, Printing, Three-Dimensional, Tomography, X-Ray Computed, Virtual Reality, Virtual reality, Female, 3D printing, Acetabular surgery, Acetabulum, Clinical Competence, Comprehension, Education, Medical, Graduate, Fracture Fixation, Internal, Inter-observer, Internship and Residency, Judet–Letournel classification, Learning Curve, Netherlands, Observer Variation, Orthopedics, Registries},
	pages = {109--116},
}

@book{mihelj_virtual_2014,
	address = {Dordrecht},
	series = {Intelligent {Systems}, {Control} and {Automation}: {Science} and {Engineering}},
	title = {Virtual {Reality} {Technology} and {Applications}},
	volume = {68},
	isbn = {978-94-007-6909-0 978-94-007-6910-6},
	url = {http://link.springer.com/10.1007/978-94-007-6910-6},
	language = {en},
	urldate = {2021-11-03},
	publisher = {Springer Netherlands},
	author = {Mihelj, Matjaž and Novak, Domen and Beguš, Samo},
	year = {2014},
	doi = {10.1007/978-94-007-6910-6},
	file = {Mihelj et al. - 2014 - Virtual Reality Technology and Applications.pdf:/home/tei/Zotero/storage/UXRZDJV5/Mihelj et al. - 2014 - Virtual Reality Technology and Applications.pdf:application/pdf},
}

@misc{noauthor_feelreal_nodate,
	title = {{FEELREAL} {Multisensory} {VR} {Mask}},
	url = {https://feelreal.com/},
	abstract = {Feelreal is the world’s first Multisensory Mask that releases smells, vibrates, and blasts your face with air or mist to make VR experiences even more immersing.},
	language = {en},
	urldate = {2021-11-03},
	file = {Snapshot:/home/tei/Zotero/storage/RH69TX6I/feelreal.com.html:text/html},
}

@misc{noauthor_oculus_nodate,
	title = {Oculus {Quest} 2: {Our} {Most} {Advanced} {New} {All}-in-{One} {VR} {Headset} {\textbar} {Oculus}},
	shorttitle = {Oculus {Quest} 2},
	url = {https://www.oculus.com/quest-2/},
	abstract = {Oculus Quest 2 is our newest, most advanced all-in-one VR system yet. Explore an expansive library of awe-inspiring games and immersive experiences with unparalleled freedom.},
	language = {en},
	urldate = {2021-11-03},
	file = {Snapshot:/home/tei/Zotero/storage/76WWZLCL/quest-2.html:text/html},
}

@article{hackett_three-dimensional_2016,
	title = {Three-{Dimensional} {Display} {Technologies} for {Anatomical} {Education}: {A} {Literature} {Review}},
	volume = {25},
	issn = {1573-1839},
	shorttitle = {Three-{Dimensional} {Display} {Technologies} for {Anatomical} {Education}},
	url = {https://doi.org/10.1007/s10956-016-9619-3},
	doi = {10.1007/s10956-016-9619-3},
	abstract = {Anatomy is a foundational component of biological sciences and medical education and is important for a variety of clinical tasks. To augment current curriculum and improve students’ spatial knowledge of anatomy, many educators, anatomists, and researchers use three-dimensional (3D) visualization technologies. This article reviews 3D display technologies and their associated assessments for anatomical education. In the first segment, the review covers the general function of displays employing 3D techniques. The second segment of the review highlights the use and assessment of 3D technology in anatomical education, focusing on factors such as knowledge gains, student perceptions, and cognitive load. The review found 32 articles on the use of 3D displays in anatomical education and another 38 articles on the assessment of 3D displays. The review shows that the majority (74 \%) of studies indicate that the use of 3D is beneficial for many tasks in anatomical education, and that student perceptions are positive toward the technology.},
	language = {en},
	number = {4},
	urldate = {2021-11-03},
	journal = {Journal of Science Education and Technology},
	author = {Hackett, Matthew and Proctor, Michael},
	month = aug,
	year = {2016},
	pages = {641--654},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/JS4CY7MQ/Hackett and Proctor - 2016 - Three-Dimensional Display Technologies for Anatomi.pdf:application/pdf},
}

@article{kooi_visual_2004,
	title = {Visual comfort of binocular and {3D} displays},
	volume = {25},
	issn = {0141-9382},
	url = {https://www.sciencedirect.com/science/article/pii/S0141938204000502},
	doi = {10.1016/j.displa.2004.07.004},
	abstract = {Imperfections in binocular image pairs can cause serious viewing discomfort. For example, in stereo vision systems eye strain is caused by unintentional mismatches between the left and right eye images (stereo imperfections). Head-mounted displays can induce eye strain due to optical misalignments. We have experimentally determined the level of (dis)comfort experienced by human observers viewing brief presentations of imperfect binocular image pairs. We used a wide range of binocular image imperfections that are representative for commonly encountered optical errors (spatial distortions: shifts, magnification, rotation, keystone), imperfect filters (photometric asymmetries: luminance, color, contrast, crosstalk), and stereoscopic disparities. The results show that nearly all binocular image asymmetries seriously reduce visual comfort if present in a large enough amount. From our data we estimate threshold values for the onset of discomfort. The database collected in this study allows a more accurate prediction of visual comfort from the specification of a given binocular viewing system. Being able to predict the level of visual discomfort from the specification of binocular viewing systems greatly helps the design and selection process. This paper provides the basis.},
	language = {en},
	number = {2},
	urldate = {2021-11-03},
	journal = {Displays},
	author = {Kooi, Frank L. and Toet, Alexander},
	month = aug,
	year = {2004},
	keywords = {3D displays, Binocular asymmetry, Binocular crosstalk, Binocular distortions, Stereoscopic vision, Visual comfort},
	pages = {99--108},
	file = {ScienceDirect Snapshot:/home/tei/Zotero/storage/ZUWPGSJG/S0141938204000502.html:text/html},
}
