
@misc{materialise_materialise_2020,
	title = {Materialise {Introduces} {VR} {Capabilities} for {Medical} {Planning} in {Mimics} {Viewer} {\textbar} {Materialise}},
	url = {https://www.materialise.com/en/press-releases/vr-capabilities-for-medical-planning-mimics-viewer},
	language = {en},
	urldate = {2021-06-01},
	author = {materialise},
	month = nov,
	year = {2020},
	file = {Snapshot:/home/tei/Zotero/storage/GQT6F984/vr-capabilities-for-medical-planning-mimics-viewer.html:text/html},
}

@article{mishra_virtual_2019,
	title = {Virtual preoperative planning and {3D} printing are valuable for the management of complex orthopaedic trauma},
	volume = {22},
	issn = {1008-1275},
	doi = {10.1016/j.cjtee.2019.07.006},
	abstract = {PURPOSE: The technology of 3D printing (3DP) exists for quite some time, but it is still not utilized to its full potential in the field of orthopaedics and traumatology, such as underestimating its worth in virtual preoperative planning (VPP) and designing various models, templates, and jigs. It can be a significant tool in the reduction of surgical morbidity and better surgical outcome avoiding various associated complications.
METHODS: An observational study was done including 91 cases of complex trauma presented in our institution requiring operative fixation. Virtual preoperative planning and 3DP were used in the management of these fractures. Surgeons managing these cases were given a set of questionnaire and responses were recorded and assessed as a quantitative data.
RESULTS: In all the 91 cases, where VPP and 3DP were used, the surgeons were satisfied with the outcome which they got intraoperatively and postoperatively. Surgical time was reduced, with a better outcome. Three dimensional models of complex fracture were helpful in understanding the anatomy and sketching out the plans for optimum reduction and fixation. The average score of the questionnaire was 4.5, out of a maximum of 6, suggesting a positive role of 3DP in orthopaedics.
CONCLUSION: 3DP is useful in complex trauma management by accurate reduction and placement of implants, reduction of surgical time and with a better outcome. Although there is an initial learning curve to understand and execute the VPP and 3DP, these become easier with practice and experience.},
	language = {eng},
	number = {6},
	journal = {Chinese Journal of Traumatology = Zhonghua Chuang Shang Za Zhi},
	author = {Mishra, Abhishek and Verma, Tarun and Vaish, Abhishek and Vaish, Riya and Vaishya, Raju and Maini, Lalit},
	month = dec,
	year = {2019},
	pmid = {31668700},
	pmcid = {PMC6921216},
	keywords = {Adult, Bone fractures, Fracture dislocation, Fracture Dislocation, Fractures, Bone, Humans, Male, Operative Time, Orthopedic Procedures, Orthopedic Surgeons, Patient Care Planning, Printing, Three-Dimensional, Surveys and Questionnaires, Three-dimensional printing, Tomography, X-Ray Computed, Treatment Outcome, Virtual Reality, Wounds and Injuries, X-ray computed tomography, Young Adult},
	pages = {350--355},
	file = {Full Text:/home/tei/Zotero/storage/TVQ3UZEY/Mishra et al. - 2019 - Virtual preoperative planning and 3D printing are .pdf:application/pdf},
}

@article{vertemati_virtual_2019,
	title = {A {Virtual} {Reality} {Environment} to {Visualize} {Three}-{Dimensional} {Patient}-{Specific} {Models} by a {Mobile} {Head}-{Mounted} {Display}},
	volume = {26},
	issn = {1553-3506},
	url = {https://doi.org/10.1177/1553350618822860},
	doi = {10.1177/1553350618822860},
	abstract = {Introduction. With the availability of low-cost head-mounted displays (HMDs), virtual reality environments (VREs) are increasingly being used in medicine for teaching and clinical purposes. Our aim was to develop an interactive, user-friendly VRE for tridimensional visualization of patient-specific organs, establishing a workflow to transfer 3-dimensional (3D) models from imaging datasets to our immersive VRE. Materials and Methods. This original VRE model was built using open-source software and a mobile HMD, Samsung Gear VR. For its validation, we enrolled 33 volunteers: morphologists (n = 11), trainee surgeons (n = 15), and expert surgeons (n = 7). They tried our VRE and then filled in an original 5-point Likert-type scale 6-item questionnaire, considering the following parameters: ease of use, anatomy comprehension compared with 2D radiological imaging, explanation of anatomical variations, explanation of surgical procedures, preoperative planning, and experience of gastrointestinal/neurological disorders. Results in the 3 groups were statistically compared using analysis of variance. Results. Using cross-sectional medical imaging, the developed VRE allowed to visualize a 3D patient-specific abdominal scene in 1 hour. Overall, the 6 items were evaluated positively by all groups; only anatomy comprehension was statistically significant different among the 3 groups. Conclusions. Our approach, based on open-source software and mobile hardware, proved to be a valid and well-appreciated system to visualize 3D patient-specific models, paving the way for a potential new tool for teaching and preoperative planning.},
	language = {en},
	number = {3},
	urldate = {2021-06-01},
	journal = {Surgical Innovation},
	author = {Vertemati, Maurizio and Cassin, Simone and Rizzetto, Francesco and Vanzulli, Angelo and Elli, Marco and Sampogna, Gianluca and Gallieni, Maurizio},
	month = jun,
	year = {2019},
	note = {Publisher: SAGE Publications Inc},
	keywords = {anatomy, head-mounted display, mobile, training, virtual reality},
	pages = {359--370},
	file = {SAGE PDF Full Text:/home/tei/Zotero/storage/8NA4Y7TR/Vertemati et al. - 2019 - A Virtual Reality Environment to Visualize Three-D.pdf:application/pdf},
}

@article{vinje_mini_nodate,
	title = {Mini invasiv behandling av brudd i hælbeinet ved hjelp av {3D} printing},
	shorttitle = {3dp for brudd i hæl},
	author = {Vinje, Tarjei},
	pages = {22},
	file = {Vinje - Mini invasiv behandling av brudd i hælbeinet ved h.pdf:/home/tei/Zotero/storage/NYXGDKQQ/Vinje - Mini invasiv behandling av brudd i hælbeinet ved h.pdf:application/pdf},
}

@article{chheang_collaborative_2021,
	title = {A collaborative virtual reality environment for liver surgery planning},
	volume = {99},
	issn = {0097-8493},
	url = {https://www.sciencedirect.com/science/article/pii/S0097849321001400},
	doi = {10.1016/j.cag.2021.07.009},
	abstract = {Surgical planning software is a key component in the treatment of tumor diseases. However, desktop-based systems provide only limited visualization and interaction opportunities. Moreover, collaborative planning among members of a surgical team is only possible to a limited extent. In this work, a collaborative virtual reality (VR) environment to assist liver surgeons in tumor surgery planning is presented. Our aim is to improve virtual resection planning between surgeons in a remote or co-located environment. The system allows surgeons to define and adjust virtual resections on patient-specific organ 3D surfaces and 2D image slices. Changes on both modalities are synchronized, which will enable surgeons to iterate and refine the resection surfaces quickly. In addition, a real-time risk map visualization is presented that displays safety margins around tumors. An evaluation performed by liver surgeons provides information on potential benefits, such as the possibility to visualize complex cases and assessing the safety-critical areas, applicability, and limitations for further improvement.},
	language = {en},
	urldate = {2021-08-30},
	journal = {Computers \& Graphics},
	author = {Chheang, Vuthea and Saalfeld, Patrick and Joeres, Fabian and Boedecker, Christian and Huber, Tobias and Huettl, Florentine and Lang, Hauke and Preim, Bernhard and Hansen, Christian},
	month = oct,
	year = {2021},
	keywords = {Human-computer interaction, Medical visualization, Surgical planning, Virtual reality},
	pages = {234--246},
	file = {ScienceDirect Full Text PDF:/home/tei/Zotero/storage/ABM86REF/Chheang et al. - 2021 - A collaborative virtual reality environment for li.pdf:application/pdf;ScienceDirect Snapshot:/home/tei/Zotero/storage/HTT3YQXH/S0097849321001400.html:text/html},
}

@misc{materialise_medical_nodate,
	title = {Medical {3D} {Printing} {\textbar} {3D} {Printing} {In} {Medical} {Field} {\textbar} {Materialise} {Medical}},
	url = {https://www.materialise.com/en/medical},
	abstract = {Premium medical 3D Printing and planning solutions. Complete 3D medical software \& services for healthcare professionals, engineers \& researchers. Better fitting implants, planning advanced clinical procedures; medical image-based planning and medical 3D printing technology is solving the most complex challenges.},
	language = {en},
	urldate = {2021-09-01},
	author = {materialise},
	file = {Snapshot:/home/tei/Zotero/storage/WPXIFYC3/medical.html:text/html},
}

@misc{dicomdirectorcom_surgeons_nodate,
	title = {Surgeons {\textbar} {Solutions} {For} {DICOM} {Done} {Better}, {Faster} + {3D} on every device},
	url = {https://www.dicomdirector.com/for-surgeons/},
	abstract = {DICOM Solution For Surgeons Viewable on Augmented, Virtual Reality devices, or on any Device. Better Surgical Planning, patient prep and more},
	language = {en-US},
	urldate = {2021-09-01},
	journal = {DICOM Director},
	author = {dicomdirector.com},
	file = {Snapshot:/home/tei/Zotero/storage/2WJMN8JV/for-surgeons.html:text/html},
}

@misc{medical_holodeck_medicalholodeck_nodate,
	title = {Medicalholodeck. {The} {Virtual} {Reality} {Platform} for {Medical} {Teamwork}.},
	url = {https://www.medicalholodeck.com/en/},
	abstract = {DICOM Viewer, human anatomy lab and 3D anatomy models for teamwork in virtual reality (VR).},
	language = {en},
	urldate = {2021-09-01},
	author = {Medical Holodeck},
	file = {Snapshot:/home/tei/Zotero/storage/I8M2GC3Z/en.html:text/html},
}

@article{chen_efficacy_2019,
	title = {The efficacy of using {3D} printing models in the treatment of fractures: a randomised clinical trial},
	volume = {20},
	issn = {1471-2474},
	shorttitle = {The efficacy of using {3D} printing models in the treatment of fractures},
	url = {https://doi.org/10.1186/s12891-019-2448-9},
	doi = {10.1186/s12891-019-2448-9},
	abstract = {The aim of this study was to evaluate the efficacy of the use of three-dimensional (3D) printing models for preoperative planning in cases of complex fracture.},
	language = {en},
	number = {1},
	urldate = {2021-09-24},
	journal = {BMC Musculoskeletal Disorders},
	author = {Chen, Chunhui and Cai, Leyi and Zheng, Wenhao and Wang, Jianshun and Guo, Xiaoshan and Chen, Hua},
	month = feb,
	year = {2019},
	pages = {65},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/XEW9GCF5/Chen et al. - 2019 - The efficacy of using 3D printing models in the tr.pdf:application/pdf},
}

@misc{noauthor_visualizing_2017,
	title = {Visualizing {MRI} \& {CT} {Scans} in {Mixed} {Reality} / {VR} / {AR}, {Part} 1: {Importing} {Data}},
	shorttitle = {Visualizing {MRI} \& {CT} {Scans} in {Mixed} {Reality} / {VR} / {AR}, {Part} 1},
	url = {https://www.andreasjakl.com/visualising-mri-ct-scans-in-mixed-reality-vr-ar-part-1-importing-data/},
	abstract = {First part in a step-by-step series to visualize MRI / CT / ultrasound data in 3D using HoloLens and Google ARCore.},
	language = {en-US},
	urldate = {2021-09-27},
	journal = {andreasjakl.com},
	month = oct,
	year = {2017},
	file = {Snapshot:/home/tei/Zotero/storage/FZ5MJC6G/visualising-mri-ct-scans-in-mixed-reality-vr-ar-part-1-importing-data.html:text/html},
}

@techreport{ceevra_inc_using_2019,
	type = {Clinical trial registration},
	title = {Using {Virtual} {Reality} ({VR}) {Models} for {Preoperative} {Planning}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03334344},
	abstract = {A prospective, randomized, controlled study designed to assess whether digital virtual reality (VR) models, created from existing CT scans and MRIs, provide surgeons with an improved understanding of their patients' anatomy, resulting in more efficient operations (robotic partial nephrectomy) and improved patient care.},
	number = {NCT03334344},
	urldate = {2021-09-26},
	institution = {clinicaltrials.gov},
	author = {{Ceevra, Inc.}},
	month = jun,
	year = {2019},
	note = {submitted: November 1, 2017},
}

@misc{noauthor_ceevra_nodate,
	title = {Ceevra {\textbar} {Advanced} {3D} {Visualization} for {Surgeons}},
	url = {https://ceevra.com/},
	language = {en-US},
	urldate = {2021-09-27},
	file = {Snapshot:/home/tei/Zotero/storage/9YFQ2EK9/ceevra.com.html:text/html},
}

@techreport{ceevra_inc_using_2019-1,
	type = {Clinical trial registration},
	title = {Using {Virtual} {Reality} ({VR}) {Models} for {Preoperative} {Planning}},
	url = {https://clinicaltrials.gov/ct2/show/NCT03334344},
	abstract = {A prospective, randomized, controlled study designed to assess whether digital virtual reality (VR) models, created from existing CT scans and MRIs, provide surgeons with an improved understanding of their patients' anatomy, resulting in more efficient operations (robotic partial nephrectomy) and improved patient care.},
	number = {NCT03334344},
	urldate = {2021-10-03},
	institution = {clinicaltrials.gov},
	author = {{Ceevra, Inc.}},
	month = jun,
	year = {2019},
	note = {submitted: November 1, 2017},
}

@article{shirk_effect_2019,
	title = {Effect of 3-{Dimensional} {Virtual} {Reality} {Models} for {Surgical} {Planning} of {Robotic}-{Assisted} {Partial} {Nephrectomy} on {Surgical} {Outcomes}: {A} {Randomized} {Clinical} {Trial}},
	volume = {2},
	issn = {2574-3805},
	shorttitle = {Effect of 3-{Dimensional} {Virtual} {Reality} {Models} for {Surgical} {Planning} of {Robotic}-{Assisted} {Partial} {Nephrectomy} on {Surgical} {Outcomes}},
	doi = {10.1001/jamanetworkopen.2019.11598},
	abstract = {Importance: Planning complex operations such as robotic-assisted partial nephrectomy requires surgeons to review 2-dimensional computed tomography or magnetic resonance images to understand 3-dimensional (3-D), patient-specific anatomy.
Objective: To determine surgical outcomes for robotic-assisted partial nephrectomy when surgeons reviewed 3-D virtual reality (VR) models during operative planning.
Design, Setting, and Participants: A single-blind randomized clinical trial was performed. Ninety-two patients undergoing robotic-assisted partial nephrectomy performed by 1 of 11 surgeons at 6 large teaching hospitals were prospectively enrolled and randomized. Enrollment and data collection occurred from October 2017 through December 2018, and data analysis was performed from December 2018 through March 2019.
Interventions: Patients were assigned to either a control group undergoing usual preoperative planning with computed tomography and/or magnetic resonance imaging only or an intervention group where imaging was supplemented with a 3-D VR model. This model was viewed on the surgeon's smartphone in regular 3-D format and in VR using a VR headset.
Main Outcomes and Measures: The primary outcome measure was operative time. It was hypothesized that the operations performed using the 3-D VR models would have shorter operative time than those performed without the models. Secondary outcomes included clamp time, estimated blood loss, and length of hospital stay.
Results: Ninety-two patients (58 men [63\%]) with a mean (SD) age of 60.9 (11.6) years were analyzed. The analysis included 48 patients randomized to the control group and 44 randomized to the intervention group. When controlling for case complexity and other covariates, patients whose surgical planning involved 3-D VR models showed differences in operative time (odds ratio [OR], 1.00; 95\% CI, 0.37-2.70; estimated OR, 2.47), estimated blood loss (OR, 1.98; 95\% CI, 1.04-3.78; estimated OR, 4.56), clamp time (OR, 1.60; 95\% CI, 0.79-3.23; estimated OR, 11.22), and length of hospital stay (OR, 2.86; 95\% CI, 1.59-5.14; estimated OR, 5.43). Estimated ORs were calculated using the parameter estimates from the generalized estimating equation model. Referent group values for each covariate and the corresponding nephrometry score were summed across the covariates and nephrometry score, and the sum was exponentiated to obtain the OR. A mean of the estimated OR weighted by sample size for each nephrometry score strata was then calculated.
Conclusions and Relevance: This large, randomized clinical trial demonstrated that patients whose surgical planning involved 3-D VR models had reduced operative time, estimated blood loss, clamp time, and length of hospital stay.
Trial Registration: ClinicalTrials.gov identifiers (1 registration per site): NCT03334344, NCT03421418, NCT03534206, NCT03542565, NCT03556943, and NCT03666104.},
	language = {eng},
	number = {9},
	journal = {JAMA network open},
	author = {Shirk, Joseph D. and Thiel, David D. and Wallen, Eric M. and Linehan, Jennifer M. and White, Wesley M. and Badani, Ketan K. and Porter, James R.},
	month = sep,
	year = {2019},
	pmid = {31532520},
	pmcid = {PMC6751754},
	keywords = {Humans, Male, Operative Time, Virtual Reality, Blood Loss, Surgical, Computer Simulation, Female, Glomerular Filtration Rate, Imaging, Three-Dimensional, Length of Stay, Middle Aged, Nephrectomy, Robotic Surgical Procedures, Single-Blind Method},
	pages = {e1911598},
	file = {Full Text:/home/tei/Zotero/storage/CUFZZM48/Shirk et al. - 2019 - Effect of 3-Dimensional Virtual Reality Models for.pdf:application/pdf},
}

@article{brouwers_what_2020,
	title = {What is the value of {3D} virtual reality in understanding acetabular fractures?},
	volume = {30},
	issn = {1633-8065},
	doi = {10.1007/s00590-019-02537-w},
	abstract = {BACKGROUND: Acetabular fractures are difficult to classify owing to the complex three-dimensional (3D) anatomy of the pelvis. 3D printing helps to understand and reliably classify acetabular fracture types. 3D-virtual reality (VR) may have comparable benefits. Our hypothesis is that 3D-VR is equivalent to 3D printing in understanding acetabular fracture patterns.
METHODS: A total of 27 observers of various experience levels from several hospitals were requested to classify twenty 3D printed and VR models according to the Judet-Letournel classification. Additionally, surgeons were asked to state their preferred surgical approach and patient positioning. Time to classify each fracture type was recorded. The cases were randomized to rule out a learning curve. Inter-observer agreement was analyzed using Fleiss' kappa statistics (κ).
RESULTS: Inter-observer agreements varied by observer group and type of model used to classify the fracture: medical students: 3D print (κ = 0.61), VR (κ = 0.41); junior surgical residents: 3D print (0.51) VR (0.54); senior surgical residents: 3D print (0.66) VR (0.52); junior surgeons: 3D print (0.56), VR (0.43); senior surgeons: 3D print (κ = 0.59), VR (κ = 0.42). Using 3D printed models, there was more agreement on the surgical approach (junior surgeons κ = 0.23, senior surgeons κ = 0.31) when compared with VR (junior surgeons κ = 0.17, senior surgeons 0.25). No difference was found in time used to classify these fractures between 3D printing and VR for all groups (P = 1.000).
CONCLUSIONS: The Judet-Letournel acetabular classification stays difficult to interpret; only moderate kappa agreements were found. We found 3D-VR inferior to 3D printing in classifying acetabular fractures. Furthermore, the current 3D-VR technology is still not practical for intra-operative use.},
	language = {eng},
	number = {1},
	journal = {European Journal of Orthopaedic Surgery \& Traumatology: Orthopedie Traumatologie},
	author = {Brouwers, Lars and Pull Ter Gunne, Albert F. and de Jongh, Mariska A. and Maal, Thomas J. J. and Vreeken, Rinaldo and van der Heijden, Frank H. W. M. and Leenen, Luke P. H. and Spanjersberg, Willem R. and van Helden, Sven H. and Verbeek, Diederik O. and Bemelman, Mike and Lansink, Koen W. W.},
	month = jan,
	year = {2020},
	pmid = {31531739},
	keywords = {Adult, Fractures, Bone, Humans, Male, Printing, Three-Dimensional, Tomography, X-Ray Computed, Virtual Reality, Virtual reality, Female, 3D printing, Acetabular surgery, Acetabulum, Clinical Competence, Comprehension, Education, Medical, Graduate, Fracture Fixation, Internal, Inter-observer, Internship and Residency, Judet–Letournel classification, Learning Curve, Netherlands, Observer Variation, Orthopedics, Registries},
	pages = {109--116},
}

@book{mihelj_virtual_2014,
	address = {Dordrecht},
	series = {Intelligent {Systems}, {Control} and {Automation}: {Science} and {Engineering}},
	title = {Virtual {Reality} {Technology} and {Applications}},
	volume = {68},
	isbn = {978-94-007-6909-0 978-94-007-6910-6},
	url = {http://link.springer.com/10.1007/978-94-007-6910-6},
	language = {en},
	urldate = {2021-11-03},
	publisher = {Springer Netherlands},
	author = {Mihelj, Matjaž and Novak, Domen and Beguš, Samo},
	year = {2014},
	doi = {10.1007/978-94-007-6910-6},
	file = {Mihelj et al. - 2014 - Virtual Reality Technology and Applications.pdf:/home/tei/Zotero/storage/UXRZDJV5/Mihelj et al. - 2014 - Virtual Reality Technology and Applications.pdf:application/pdf},
}

@misc{noauthor_feelreal_nodate,
	title = {{FEELREAL} {Multisensory} {VR} {Mask}},
	url = {https://feelreal.com/},
	abstract = {Feelreal is the world’s first Multisensory Mask that releases smells, vibrates, and blasts your face with air or mist to make VR experiences even more immersing.},
	language = {en},
	urldate = {2021-11-03},
	file = {Snapshot:/home/tei/Zotero/storage/RH69TX6I/feelreal.com.html:text/html},
}

@misc{noauthor_oculus_nodate,
	title = {Oculus {Quest} 2: {Our} {Most} {Advanced} {New} {All}-in-{One} {VR} {Headset} {\textbar} {Oculus}},
	shorttitle = {Oculus {Quest} 2},
	url = {https://www.oculus.com/quest-2/},
	abstract = {Oculus Quest 2 is our newest, most advanced all-in-one VR system yet. Explore an expansive library of awe-inspiring games and immersive experiences with unparalleled freedom.},
	language = {en},
	urldate = {2021-11-03},
	file = {Snapshot:/home/tei/Zotero/storage/76WWZLCL/quest-2.html:text/html},
}

@article{hackett_three-dimensional_2016,
	title = {Three-{Dimensional} {Display} {Technologies} for {Anatomical} {Education}: {A} {Literature} {Review}},
	volume = {25},
	issn = {1573-1839},
	shorttitle = {Three-{Dimensional} {Display} {Technologies} for {Anatomical} {Education}},
	url = {https://doi.org/10.1007/s10956-016-9619-3},
	doi = {10.1007/s10956-016-9619-3},
	abstract = {Anatomy is a foundational component of biological sciences and medical education and is important for a variety of clinical tasks. To augment current curriculum and improve students’ spatial knowledge of anatomy, many educators, anatomists, and researchers use three-dimensional (3D) visualization technologies. This article reviews 3D display technologies and their associated assessments for anatomical education. In the first segment, the review covers the general function of displays employing 3D techniques. The second segment of the review highlights the use and assessment of 3D technology in anatomical education, focusing on factors such as knowledge gains, student perceptions, and cognitive load. The review found 32 articles on the use of 3D displays in anatomical education and another 38 articles on the assessment of 3D displays. The review shows that the majority (74 \%) of studies indicate that the use of 3D is beneficial for many tasks in anatomical education, and that student perceptions are positive toward the technology.},
	language = {en},
	number = {4},
	urldate = {2021-11-03},
	journal = {Journal of Science Education and Technology},
	author = {Hackett, Matthew and Proctor, Michael},
	month = aug,
	year = {2016},
	pages = {641--654},
	file = {Springer Full Text PDF:/home/tei/Zotero/storage/JS4CY7MQ/Hackett and Proctor - 2016 - Three-Dimensional Display Technologies for Anatomi.pdf:application/pdf},
}

@article{kooi_visual_2004,
	title = {Visual comfort of binocular and {3D} displays},
	volume = {25},
	issn = {0141-9382},
	url = {https://www.sciencedirect.com/science/article/pii/S0141938204000502},
	doi = {10.1016/j.displa.2004.07.004},
	abstract = {Imperfections in binocular image pairs can cause serious viewing discomfort. For example, in stereo vision systems eye strain is caused by unintentional mismatches between the left and right eye images (stereo imperfections). Head-mounted displays can induce eye strain due to optical misalignments. We have experimentally determined the level of (dis)comfort experienced by human observers viewing brief presentations of imperfect binocular image pairs. We used a wide range of binocular image imperfections that are representative for commonly encountered optical errors (spatial distortions: shifts, magnification, rotation, keystone), imperfect filters (photometric asymmetries: luminance, color, contrast, crosstalk), and stereoscopic disparities. The results show that nearly all binocular image asymmetries seriously reduce visual comfort if present in a large enough amount. From our data we estimate threshold values for the onset of discomfort. The database collected in this study allows a more accurate prediction of visual comfort from the specification of a given binocular viewing system. Being able to predict the level of visual discomfort from the specification of binocular viewing systems greatly helps the design and selection process. This paper provides the basis.},
	language = {en},
	number = {2},
	urldate = {2021-11-03},
	journal = {Displays},
	author = {Kooi, Frank L. and Toet, Alexander},
	month = aug,
	year = {2004},
	keywords = {3D displays, Binocular asymmetry, Binocular crosstalk, Binocular distortions, Stereoscopic vision, Visual comfort},
	pages = {99--108},
	file = {ScienceDirect Snapshot:/home/tei/Zotero/storage/ZUWPGSJG/S0141938204000502.html:text/html},
}

@article{bradley_history_2008,
	title = {History of {Medical} {Imaging}},
	volume = {152},
	journal = {Proceedings of the American Philosophical Society},
	author = {Bradley, William},
	month = sep,
	year = {2008},
	pages = {349--61},
	file = {Full Text PDF:/home/tei/Zotero/storage/37G2IPAH/Bradley - 2008 - History of Medical Imaging.pdf:application/pdf},
}

@article{king_vr_1993,
	title = {{VR} use in education},
	volume = {7},
	issn = {0922-6567, 1573-0573},
	url = {http://link.springer.com/10.1007/BF00398472},
	doi = {10.1007/BF00398472},
	abstract = {Since the first time the term "Virtual Reality" (VR) has been used back in the 60s, VR has evolved in different manners becoming more and more similar to the real world. Two different kinds of VR can be identified: non-immersive and immersive. The former is a computer-based environment that can simulate places in the real or imagined worlds; the latter takes the idea even further by giving the perception of being physically present in the non-physical world. While non-immersive VR can be based on a standard computer, immersive VR is still evolving as the needed devices are becoming more user friendly and economically accessible. In the past, there was a major difficulty about using equipment such as a helmet with goggles, while now new devices are being developed to make usability better for the user. VR, which is based on three basic principles: Immersion, Interaction, and User involvement with the environment and narrative, offers a very high potential in education by making learning more motivating and engaging. Up to now, the use of immersive-VR in educational games has been limited due to high prices of the devices and their limited usability. Now new tools like the commercial "Oculus Rift", make it possible to access immersive-VR in lots of educational situations. This paper reports a survey on the scientific literature on the advantages and potentials in the use of Immersive Virtual Reality in Education in the last two years (2013-14). It shows how VR in general, and immersive VR in particular, has been used mostly for adult training in special situations or for university students. It then focuses on the possible advantages and drawbacks of its use in education with reference to different classes of users like children and some kinds of cognitive disabilities (with particular reference to the Down syndrome). It concludes outlining strategies that could be carried out to verify these ideas.},
	language = {en},
	number = {4},
	urldate = {2021-11-11},
	journal = {Machine Translation},
	author = {King, Margaret},
	year = {1993},
	pages = {273--279},
	file = {King - 1993 - State of the art and perspectives.pdf:/home/tei/Zotero/storage/XJ6CXJD3/King - 1993 - State of the art and perspectives.pdf:application/pdf},
}

@inproceedings{freina_immersive_2015,
	address = {Bucharest, Romania},
	title = {Immersive {Virtual} {Reality} in {Education}: {State} of the {Art} and {Perspectives}},
	volume = {1},
	copyright = {Copyright "Carol I" National Defence University 2015},
	shorttitle = {A {Literature} {Review} on {Immersive} {Virtual} {Reality} in {Education}},
	url = {https://www.proquest.com/docview/1681252932/abstract/D4B2F610BED4D5BPQ/1},
	abstract = {Since the first time the term "Virtual Reality" (VR) has been used back in the 60s, VR has evolved in different manners becoming more and more similar to the real world. Two different kinds of VR can be identified: non-immersive and immersive. The former is a computer-based environment that can simulate places in the real or imagined worlds; the latter takes the idea even further by giving the perception of being physically present in the non-physical world. While non-immersive VR can be based on a standard computer, immersive VR is still evolving as the needed devices are becoming more user friendly and economically accessible. In the past, there was a major difficulty about using equipment such as a helmet with goggles, while now new devices are being developed to make usability better for the user. VR, which is based on three basic principles: Immersion, Interaction, and User involvement with the environment and narrative, offers a very high potential in education by making learning more motivating and engaging. Up to now, the use of immersive-VR in educational games has been limited due to high prices of the devices and their limited usability. Now new tools like the commercial "Oculus Rift", make it possible to access immersive-VR in lots of educational situations. This paper reports a survey on the scientific literature on the advantages and potentials in the use of Immersive Virtual Reality in Education in the last two years (2013-2014). It shows how VR in general, and immersive VR in particular, has been used mostly for adult training in special situations or for university students. It then focuses on the possible advantages and drawbacks of its use in education with reference to different classes of users like children and some kinds of cognitive disabilities (with particular reference to the Down syndrome). It concludes outlining strategies that could be carried out to verify these ideas.},
	language = {English},
	urldate = {2021-11-11},
	booktitle = {The {International} {Scientific} {Conference} {eLearning} and {Software} for {Education}},
	publisher = {"Carol I" National Defence University},
	author = {Freina, Laura and Ott, Michela},
	year = {2015},
	note = {Num Pages: 9},
	keywords = {Virtual reality, Cognitive style, Education, Education--Computer Applications, Experiments, Handicapped accessibility, Literature reviews},
	pages = {133--141},
	file = {Full Text PDF:/home/tei/Zotero/storage/W8BVMB96/Freina and Ott - 2015 - A Literature Review on Immersive Virtual Reality i.pdf:application/pdf},
}

@article{merhi_motion_2007,
	title = {Motion {Sickness}, {Console} {Video} {Games}, and {Head}-{Mounted} {Displays}},
	volume = {49},
	issn = {0018-7208, 1547-8181},
	url = {http://journals.sagepub.com/doi/10.1518/001872007X230262},
	doi = {10.1518/001872007X230262},
	abstract = {Objective: We evaluated the nauseogenic properties of commercial console video games (i.e., games that are sold to the public) when presented through a head-mounted display. Background: Anecdotal reports suggest that motion sickness may occur among players of contemporary commercial console video games. Methods: Participants played standard console video games using an Xbox game system. We varied the participants' posture (standing vs. sitting) and the game (two Xbox games). Participants played for up to 50 min and were asked to discontinue if they experienced any symptoms of motion sickness. Results: Sickness occurred in all conditions, but it was more common during standing. During seated play there were significant differences in head motion between sick and well participants before the onset of motion sickness. Conclusion: The results indicate that commercial console video game systems can induce motion sickness when presented via a head-mounted display and support the hypothesis that motion sickness is preceded by instability in the control of seated posture. Application: Potential applications of this research include changes in the design of console video games and recommendations for how such systems should be used.},
	language = {en},
	number = {5},
	urldate = {2021-11-11},
	journal = {Human Factors: The Journal of the Human Factors and Ergonomics Society},
	author = {Merhi, Omar and Faugloire, Elise and Flanagan, Moira and Stoffregen, Thomas A.},
	month = oct,
	year = {2007},
	pages = {920--934},
	file = {Merhi et al. - 2007 - Motion Sickness, Console Video Games, and Head-Mou.pdf:/home/tei/Zotero/storage/R7WEBVK8/Merhi et al. - 2007 - Motion Sickness, Console Video Games, and Head-Mou.pdf:application/pdf},
}

@misc{lang_introduction_2013,
	title = {An {Introduction} to {Positional} {Tracking} and {Degrees} of {Freedom} ({DOF})},
	url = {https://www.roadtovr.com/introduction-positional-tracking-degrees-freedom-dof/},
	abstract = {Positional tracking and degrees of freedom are important concepts needed for understanding how people interact in virtual reality games and other VR spaces.},
	language = {en-US},
	urldate = {2021-11-11},
	journal = {Road to VR},
	author = {Lang, Ben},
	month = feb,
	year = {2013},
	note = {Section: Body Tracking},
	file = {Snapshot:/home/tei/Zotero/storage/Y8UE9GUV/introduction-positional-tracking-degrees-freedom-dof.html:text/html},
}

@article{chang_virtual_2020,
	title = {Virtual {Reality} {Sickness}: {A} {Review} of {Causes} and {Measurements}},
	volume = {36},
	issn = {1044-7318},
	shorttitle = {Virtual {Reality} {Sickness}},
	url = {https://doi.org/10.1080/10447318.2020.1778351},
	doi = {10.1080/10447318.2020.1778351},
	abstract = {In virtual reality (VR), users can experience symptoms of motion sickness, which is referred to as VR sickness or cybersickness. The symptoms include but are not limited to eye fatigue, disorientation, and nausea, which can impair the VR experience of users. Though many studies have attempted to reduce the discomfort, they produced conflicting results with varying degrees of VR sickness. In particular, a visually improved VR does not necessarily result in decreased VR sickness. To understand these unexpected results, we surveyed the causes of VR sickness and measurement of symptoms. We reorganized the causes of the VR sickness into three major factors (hardware, content, and human factors) and investigated the sub-component of each factor. We then surveyed frequently used measures of VR sickness, both subjective and objective approaches. We also investigated emerging approaches for reducing VR sickness and proposed a multimodal fidelity hypothesis to give an insight into future studies.},
	number = {17},
	urldate = {2021-11-15},
	journal = {International Journal of Human–Computer Interaction},
	author = {Chang, Eunhee and Kim, Hyun Taek and Yoo, Byounghyun},
	month = oct,
	year = {2020},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/10447318.2020.1778351},
	pages = {1658--1682},
	file = {Full Text PDF:/home/tei/Zotero/storage/TNW56XLB/Chang et al. - 2020 - Virtual Reality Sickness A Review of Causes and M.pdf:application/pdf;Snapshot:/home/tei/Zotero/storage/8JF5HB3H/10447318.2020.html:text/html},
}

@misc{noauthor_use_2021,
	title = {The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation: a scoping review},
	author = {, Sang-Hee Park2, Todd P. Chang3, Timothy Jung4 {and} Ralph MacKinnon1, Katherine Kuyt1},
	year = {2021},
}

@article{kuyt_use_2021,
	title = {The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation: a scoping review},
	volume = {6},
	issn = {2059-0628},
	shorttitle = {The use of virtual reality and augmented reality to enhance cardio-pulmonary resuscitation},
	url = {https://doi.org/10.1186/s41077-021-00158-0},
	doi = {10.1186/s41077-021-00158-0},
	abstract = {Virtual reality (VR) and augmented reality (AR) have been proposed as novel methods to enhance cardio-pulmonary resuscitation (CPR) performance and increase engagement with CPR training. A scoping review was conducted to map the global evolution of these new approaches to CPR training, to assess their efficacy and determine future directions to meet gaps in current knowledge.},
	number = {1},
	urldate = {2021-11-15},
	journal = {Advances in Simulation},
	author = {Kuyt, Katherine and Park, Sang-Hee and Chang, Todd P. and Jung, Timothy and MacKinnon, Ralph},
	month = apr,
	year = {2021},
	keywords = {Virtual reality, Augmented reality, Cardiopulmonary resuscitation, Simulation},
	pages = {11},
	file = {Full Text PDF:/home/tei/Zotero/storage/5EED2F7U/Kuyt et al. - 2021 - The use of virtual reality and augmented reality t.pdf:application/pdf;Snapshot:/home/tei/Zotero/storage/BC2IJARK/s41077-021-00158-0.html:text/html},
}

@misc{noauthor_notitle_nodate,
}

@book{swiontkowski_manual_2013,
	address = {Philadelphia},
	edition = {7th ed},
	title = {Manual of orthopaedics},
	isbn = {978-1-4511-1592-5},
	publisher = {Wolters Kluwer/Lippincott Williams \& Wilkins Health},
	editor = {Swiontkowski, Marc F. and Stovitz, Steven D.},
	year = {2013},
	keywords = {Fractures, Bone, Orthopedics, Handbooks, injuries, methods, Musculoskeletal System, rehabilitation},
}

@article{napolitano_challenging_2010,
	title = {Challenging {Issues} in {Surgical} {Critical} {Care}, {Trauma}, and {Acute} {Care} {Surgery}: {A} {Report} {From} the {Critical} {Care} {Committee} of the {American} {Association} for the {Surgery} of {Trauma}},
	volume = {69},
	issn = {2163-0755},
	shorttitle = {Challenging {Issues} in {Surgical} {Critical} {Care}, {Trauma}, and {Acute} {Care} {Surgery}},
	url = {https://journals.lww.com/jtrauma/FullText/2010/12000/Challenging_Issues_in_Surgical_Critical_Care,.48.aspx},
	doi = {10.1097/TA.0b013e3182011089},
	abstract = {Critical care workforce analyses estimate a 35\% shortage of intensivists by 2020 as a result of the aging population and the growing demand for greater utilization of intensivists. Surgical critical care in the U.S. is particularly challenged by a significant shortfall of surgical intensivists, with only 2586 surgeons currently certified in surgical critical care by the American Board of Surgery, and even fewer surgeons (1204) recertified in surgical critical care as of 2009. Surgical critical care fellows (160 in 2009) represent only 7.6\% of all critical care trainees (2109 in 2009), with the largest number of critical care fellowship positions in internal medicine (1472, 69.8\%). Traditional trauma fellowships have now transitioned into Surgical Critical Care or Acute Care Surgery (trauma, surgical critical care, emergency surgery) fellowships. Since adult critical care services are a large, expensive part of U.S. healthcare and workforce shortages continue to impact our healthcare system, recommendations for regionalization of critical care services in the U.S. is considered. The Critical Care Committee of the AAST has compiled national data regarding these important issues that face us in surgical critical care, trauma and acute care surgery, and discuss potential solutions for these issues.},
	language = {en-US},
	number = {6},
	urldate = {2021-11-27},
	journal = {Journal of Trauma and Acute Care Surgery},
	author = {Napolitano, Lena M. and Fulda, Gerard J. and Davis, Kimberly A. and Ashley, Dennis W. and Friese, Randall and Van Way, Charles W. III and Meredith, J. Wayne and Fabian, Timothy C. and Jurkovich, Gregory J. and Peitzman, Andrew B.},
	month = dec,
	year = {2010},
	pages = {1619--1633},
	file = {Snapshot:/home/tei/Zotero/storage/KS47CB8V/Challenging_Issues_in_Surgical_Critical_Care,.48.html:text/html},
}

@article{chougule_conversions_2013,
	title = {Conversions of {CT} {Scan} {Images} into 3 {D} {Point} {Cloud} {Data} for the {Development} of 3 {D} {Solid} {Model} using {B}-{Rep} {Scheme}},
	url = {https://www.semanticscholar.org/paper/Conversions-of-CT-Scan-Images-into-3-D-Point-Cloud-Chougule-Mulay/d4875163b4162ba44843a326490f20d6c7fa33e7},
	abstract = {This paper deals with generation of B-spline curves from non-invasive medical images viz. This paper deals with generation of B-spline curves from non-invasive medical images viz. CT / MRI scans. The volumetric data i.e. voxel and triangular facet triangle based models are primarily used for bio-modeling and visualization, which requires huge memory space. On the other side, recent advances in CAD technology facilitate design, prototyping and manufacturing of any object having freeform surfaces. These CAD-based solid modeling is based on boundary representation (B-rep) techniques. Image Processing techniques are proposed to extract point cloud data from stalk of CT scan images. These points are further preprocessed for sorting, smoothening and B spline curve fitting. This method facilitates the construction of the model by minimizing the size of the files and ensuring the closure of bounding surfaces.},
	language = {en},
	urldate = {2021-12-01},
	journal = {undefined},
	author = {Chougule and Mulay and Ahuja, N.},
	year = {2013},
	file = {Snapshot:/home/tei/Zotero/storage/CRBBEDUT/d4875163b4162ba44843a326490f20d6c7fa33e7.html:text/html},
}

@inproceedings{chougule_conversions_2013-1,
	title = {Conversions of {CT} {Scan} {Images} into {3D} {Point} {Cloud} {Data} for the {Development} of {3D} {Solid} {Model} using {B}-{Rep} {Scheme}},
	abstract = {This paper deals with generation of B-spline curves from non-invasive medical images viz. CT / MRI scans. The volumetric data i.e. voxel and triangular facet triangle based models are primarily used for bio-modeling and visualization, which requires huge memory space. On the other side, recent advances in CAD technology facilitate design, prototyping and manufacturing of any object having freeform surfaces. These CAD-based solid modeling is based on boundary representation (B-rep) techniques. Image Processing techniques are proposed to extract point cloud data from stalk of CT scan images. These points are further preprocessed for sorting, smoothening and B spline curve fitting. This method facilitates the construction of the model by minimizing the size of the files and ensuring the closure of bounding surfaces.},
	author = {Chougule, Vikas and Mulay, Arati and Ahuja, B.},
	month = dec,
	year = {2013},
	file = {Full Text PDF:/home/tei/Zotero/storage/XZRHE5CB/Chougule et al. - 2013 - Conversions of CT Scan Images into 3D Point Cloud .pdf:application/pdf},
}

@incollection{zhang_1_2008,
	address = {Burlington},
	series = {Biomedical {Engineering}},
	title = {1 - {Medical} {Imaging}},
	isbn = {978-0-12-373583-6},
	url = {https://www.sciencedirect.com/science/article/pii/B9780123735836500050},
	abstract = {Medical imaging forms a key part of clinical diagnosis, and improvements in the quality and type of information available from such images have extended the diagnostic accuracy and range of new applications in health care. Medical imaging plays an important role in neurology, cardiology, and cancer centers. This chapter provides a brief overview of the basic physics, instrumentation, and clinical applications of each imaging modality and recent technological advances. Planar X-ray imaging is used for diagnosing bone breaks, lung disease, a number of gastrointestinal (GI) diseases (fluoroscopy), and conditions of the genitourinary tract, such as kidney stones. In contrast to X-ray, ultrasound, and MRI, nuclear medicine imaging techniques do not produce an anatomical map of the body, but instead image the spatial distribution of radioactive materials that are introduced into the body. Ultrasound is non-ionizing, real-time, portable, and inexpensive compared with other clinical imaging modalities. Ultrasound is particularly functional for obstetrics and quantification of blood flow using Doppler measurements. The major uses of MRI are in the areas of brain disease, spinal disorders, angiography, cardiac assessment, and musculoskeletal damage. Diffuse Optical Imaging is characterized by its noninvasive nature, chemical specificity, and good temporal resolution. NIR methods are used in mammography and real-time monitoring of blood oxygenation levels of patients during medical procedures.},
	language = {en},
	urldate = {2021-12-01},
	booktitle = {Biomedical {Information} {Technology}},
	publisher = {Academic Press},
	author = {Zhang, Xiaofeng and Smith, Nadine and Webb, Andrew},
	editor = {Feng, David Dagan},
	month = jan,
	year = {2008},
	doi = {10.1016/B978-012373583-6.50005-0},
	pages = {3--27},
	file = {ScienceDirect Snapshot:/home/tei/Zotero/storage/IZV9885B/B9780123735836500050.html:text/html},
}

@book{suetens_fundamentals_2017,
	title = {Fundamentals of {Medical} {Imaging}},
	isbn = {978-1-107-15978-5},
	abstract = {This third edition provides a concise and generously illustrated survey of the complete field of medical imaging and image computing, explaining the mathematical and physical principles and giving the reader a clear understanding of how images are obtained and interpreted. Medical imaging and image computing are rapidly evolving fields, and this edition has been updated with the latest developments in the field, as well as new images and animations. An introductory chapter on digital image processing is followed by chapters on the imaging modalities: radiography, CT, MRI, nuclear medicine and ultrasound. Each chapter covers the basic physics and interaction with tissue, the image reconstruction process, image quality aspects, modern equipment, clinical applications, and biological effects and safety issues. Subsequent chapters review image computing and visualization for diagnosis and treatment. Engineers, physicists and clinicians at all levels will find this new edition an invaluable aid in understanding the principles of imaging and their clinical applications.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Suetens, Paul},
	month = may,
	year = {2017},
	note = {Google-Books-ID: U11EDgAAQBAJ},
	keywords = {Medical / Diagnostic Imaging / General, Medical / Radiology, Radiotherapy \& Nuclear Medicine},
}

@book{hamblen_outline_2010,
	edition = {14. edition},
	title = {outline of orthopaedics},
	author = {Hamblen, David L. and Simpson, A Hamish R.W.},
	year = {2010},
}

@article{fishman_volume_2006,
	title = {Volume {Rendering} versus {Maximum} {Intensity} {Projection} in {CT} {Angiography}: {What} {Works} {Best}, {When}, and {Why}},
	volume = {26},
	issn = {0271-5333},
	shorttitle = {Volume {Rendering} versus {Maximum} {Intensity} {Projection} in {CT} {Angiography}},
	url = {https://pubs.rsna.org/doi/10.1148/rg.263055186},
	doi = {10.1148/rg.263055186},
	abstract = {The introduction and widespread availability of 16-section multi–detector row computed tomographic (CT) technology and, more recently, 64-section scanners, has greatly advanced the role of CT angiography in clinical practice. CT angiography has become a key component of state-of-the-art imaging, with applications ranging from oncology (eg, staging of pancreatic or renal cancer) to classic vascular imaging (eg, evaluation of aortic aneurysms and renal artery stenoses) as well as newer techniques such as coronary artery imaging and peripheral runoff studies. With an average of 400–1000 images in each volume data set, three-dimensional postprocessing is crucial to volume visualization. Radiologists now have workstations that provide capabilities for evaluation of these data sets by using a range of software programs and processing tools. Although different systems have unique capabilities and functionality, all provide the options of volume rendering and maximum intensity projection for image display and analysis. These two postprocessing techniques have different advantages and disadvantages when used in clinical practice, and it is important that radiologists understand when and how each technique should be used.

© RSNA, 2006},
	number = {3},
	urldate = {2021-12-06},
	journal = {RadioGraphics},
	author = {Fishman, Elliot K. and Ney, Derek R. and Heath, David G. and Corl, Frank M. and Horton, Karen M. and Johnson, Pamela T.},
	month = may,
	year = {2006},
	note = {Publisher: Radiological Society of North America},
	pages = {905--922},
	file = {Full Text PDF:/home/tei/Zotero/storage/7PCVKPLZ/Fishman et al. - 2006 - Volume Rendering versus Maximum Intensity Projecti.pdf:application/pdf},
}

@misc{noauthor_dicom_nodate,
	title = {{DICOM}},
	url = {https://www.dicomstandard.org/},
	urldate = {2022-01-21},
	file = {DICOM:/home/tei/Zotero/storage/JSCFSF4J/www.dicomstandard.org.html:text/html},
}

@misc{noauthor_stl_2019,
	type = {web page},
	title = {{STL} ({STereoLithography}) {File} {Format} {Family}},
	copyright = {Text is U.S. government work},
	url = {https://www.loc.gov/preservation/digital/formats/fdd/fdd000504.shtml},
	abstract = {Format Description for STL\_family -- an openly documented plain text format for describing an object as a triangular mesh, i.e., as a representation of a 3-dimensional surface geometry in triangular facets. Each facet is described by a perpendicular (normal) direction and three points representing the vertices (corners) of the , triangle. The STL format was developed for stereolithography, a form of 3D printing, in the late 1980s.},
	language = {eng},
	urldate = {2022-01-21},
	month = sep,
	year = {2019},
	file = {Snapshot:/home/tei/Zotero/storage/AJ2XEQUU/fdd000504.html:text/html},
}

@misc{aldandarawy_unity_2019,
	title = {Unity {Cross} {Section} {Shader} {Using} {Shader} {Graph}},
	url = {https://codeburst.io/unity-cross-section-shader-using-shader-graph-31c3fed0fa4f},
	abstract = {F ew years back, I wrote a simple cross section shader in unity using Surface shader, unfortunately  that shader didn’t support different…},
	language = {en},
	urldate = {2022-01-27},
	journal = {Medium},
	author = {Aldandarawy, Abdullah},
	month = dec,
	year = {2019},
	file = {Snapshot:/home/tei/Zotero/storage/KWYJCL3S/unity-cross-section-shader-using-shader-graph-31c3fed0fa4f.html:text/html},
}

@misc{noauthor_mirror_nodate,
	title = {Mirror {Networking} – {Open} {Source} {Networking} for {Unity}},
	url = {https://mirror-networking.com/},
	language = {en-US},
	urldate = {2022-01-31},
	file = {Snapshot:/home/tei/Zotero/storage/25VSQ58L/mirror-networking.com.html:text/html},
}

@misc{technologies_unity_nodate,
	title = {Unity - {Manual}: {Unity} {XR} {Input}},
	shorttitle = {Unity - {Manual}},
	url = {https://docs.unity3d.com/Manual/xr_input.html},
	language = {en},
	urldate = {2022-02-02},
	author = {Technologies, Unity},
	file = {Snapshot:/home/tei/Zotero/storage/X33YKRX5/xr_input.html:text/html},
}
